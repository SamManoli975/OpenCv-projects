{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                860       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1125 (4.39 KB)\n",
      "Trainable params: 1125 (4.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.6088 - accuracy: 0.2820\n",
      "Epoch 1: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 4s 28ms/step - loss: 1.6088 - accuracy: 0.2820 - val_loss: 1.5222 - val_accuracy: 0.3288\n",
      "Epoch 2/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 1.4932 - accuracy: 0.3265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.4918 - accuracy: 0.3274 - val_loss: 1.4319 - val_accuracy: 0.3828\n",
      "Epoch 3/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 1.4120 - accuracy: 0.3630\n",
      "Epoch 3: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.4095 - accuracy: 0.3642 - val_loss: 1.3420 - val_accuracy: 0.4303\n",
      "Epoch 4/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 1.3450 - accuracy: 0.3675\n",
      "Epoch 4: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.3424 - accuracy: 0.3683 - val_loss: 1.2636 - val_accuracy: 0.4633\n",
      "Epoch 5/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 1.2974 - accuracy: 0.4108\n",
      "Epoch 5: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.2885 - accuracy: 0.4199 - val_loss: 1.2091 - val_accuracy: 0.5915\n",
      "Epoch 6/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 1.2389 - accuracy: 0.4548\n",
      "Epoch 6: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.2358 - accuracy: 0.4554 - val_loss: 1.1596 - val_accuracy: 0.6132\n",
      "Epoch 7/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.2046 - accuracy: 0.4790\n",
      "Epoch 7: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.2046 - accuracy: 0.4790 - val_loss: 1.1174 - val_accuracy: 0.6632\n",
      "Epoch 8/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 1.1703 - accuracy: 0.4980\n",
      "Epoch 8: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.1702 - accuracy: 0.4970 - val_loss: 1.0739 - val_accuracy: 0.6600\n",
      "Epoch 9/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 1.1457 - accuracy: 0.5050\n",
      "Epoch 9: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1428 - accuracy: 0.5099 - val_loss: 1.0329 - val_accuracy: 0.6753\n",
      "Epoch 10/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 1.1020 - accuracy: 0.5350\n",
      "Epoch 10: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1035 - accuracy: 0.5333 - val_loss: 0.9923 - val_accuracy: 0.6962\n",
      "Epoch 11/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 1.0948 - accuracy: 0.5366\n",
      "Epoch 11: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0961 - accuracy: 0.5358 - val_loss: 0.9623 - val_accuracy: 0.6938\n",
      "Epoch 12/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 1.0621 - accuracy: 0.5584\n",
      "Epoch 12: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0625 - accuracy: 0.5575 - val_loss: 0.9246 - val_accuracy: 0.7051\n",
      "Epoch 13/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.0541 - accuracy: 0.5565\n",
      "Epoch 13: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0541 - accuracy: 0.5565 - val_loss: 0.8866 - val_accuracy: 0.7156\n",
      "Epoch 14/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 1.0404 - accuracy: 0.5625\n",
      "Epoch 14: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0335 - accuracy: 0.5688 - val_loss: 0.8593 - val_accuracy: 0.7309\n",
      "Epoch 15/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9928 - accuracy: 0.5851\n",
      "Epoch 15: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9934 - accuracy: 0.5847 - val_loss: 0.8304 - val_accuracy: 0.7284\n",
      "Epoch 16/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.9782 - accuracy: 0.6034\n",
      "Epoch 16: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9808 - accuracy: 0.6011 - val_loss: 0.8074 - val_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.9572 - accuracy: 0.6000\n",
      "Epoch 17: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9572 - accuracy: 0.6000 - val_loss: 0.7729 - val_accuracy: 0.7526\n",
      "Epoch 18/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.9414 - accuracy: 0.5951\n",
      "Epoch 18: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9411 - accuracy: 0.5954 - val_loss: 0.7475 - val_accuracy: 0.7583\n",
      "Epoch 19/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.9321 - accuracy: 0.6100\n",
      "Epoch 19: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9282 - accuracy: 0.6126 - val_loss: 0.7232 - val_accuracy: 0.7695\n",
      "Epoch 20/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.9215 - accuracy: 0.6134\n",
      "Epoch 20: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9190 - accuracy: 0.6137 - val_loss: 0.7064 - val_accuracy: 0.7720\n",
      "Epoch 21/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.9166 - accuracy: 0.6152\n",
      "Epoch 21: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9104 - accuracy: 0.6183 - val_loss: 0.6887 - val_accuracy: 0.8042\n",
      "Epoch 22/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8945 - accuracy: 0.6336\n",
      "Epoch 22: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8945 - accuracy: 0.6336 - val_loss: 0.6695 - val_accuracy: 0.7840\n",
      "Epoch 23/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.8863 - accuracy: 0.6250\n",
      "Epoch 23: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.8821 - accuracy: 0.6263 - val_loss: 0.6572 - val_accuracy: 0.8268\n",
      "Epoch 24/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.8770 - accuracy: 0.6385\n",
      "Epoch 24: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8731 - accuracy: 0.6390 - val_loss: 0.6324 - val_accuracy: 0.8292\n",
      "Epoch 25/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8644 - accuracy: 0.6409\n",
      "Epoch 25: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8640 - accuracy: 0.6414 - val_loss: 0.6207 - val_accuracy: 0.8235\n",
      "Epoch 26/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.8566 - accuracy: 0.6476\n",
      "Epoch 26: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8578 - accuracy: 0.6457 - val_loss: 0.6066 - val_accuracy: 0.8461\n",
      "Epoch 27/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.8597 - accuracy: 0.6479\n",
      "Epoch 27: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8574 - accuracy: 0.6500 - val_loss: 0.5982 - val_accuracy: 0.8590\n",
      "Epoch 28/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8249 - accuracy: 0.6686\n",
      "Epoch 28: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8239 - accuracy: 0.6694 - val_loss: 0.5775 - val_accuracy: 0.8413\n",
      "Epoch 29/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.8388 - accuracy: 0.6533\n",
      "Epoch 29: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8395 - accuracy: 0.6530 - val_loss: 0.5730 - val_accuracy: 0.8662\n",
      "Epoch 30/1000\n",
      "16/30 [===============>..............] - ETA: 0s - loss: 0.8440 - accuracy: 0.6631\n",
      "Epoch 30: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8307 - accuracy: 0.6680 - val_loss: 0.5715 - val_accuracy: 0.8574\n",
      "Epoch 31/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7977 - accuracy: 0.6796\n",
      "Epoch 31: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7977 - accuracy: 0.6796 - val_loss: 0.5508 - val_accuracy: 0.8678\n",
      "Epoch 32/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.8302 - accuracy: 0.6549\n",
      "Epoch 32: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8280 - accuracy: 0.6570 - val_loss: 0.5413 - val_accuracy: 0.8646\n",
      "Epoch 33/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.7938 - accuracy: 0.6794\n",
      "Epoch 33: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7958 - accuracy: 0.6772 - val_loss: 0.5308 - val_accuracy: 0.8678\n",
      "Epoch 34/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.7995 - accuracy: 0.6731\n",
      "Epoch 34: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7932 - accuracy: 0.6766 - val_loss: 0.5210 - val_accuracy: 0.8695\n",
      "Epoch 35/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7745 - accuracy: 0.6853\n",
      "Epoch 35: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7758 - accuracy: 0.6866 - val_loss: 0.5048 - val_accuracy: 0.8735\n",
      "Epoch 36/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.7837 - accuracy: 0.6859\n",
      "Epoch 36: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7821 - accuracy: 0.6860 - val_loss: 0.5023 - val_accuracy: 0.8751\n",
      "Epoch 37/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.7823 - accuracy: 0.6828\n",
      "Epoch 37: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7843 - accuracy: 0.6825 - val_loss: 0.5018 - val_accuracy: 0.8799\n",
      "Epoch 38/1000\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.7688 - accuracy: 0.6910\n",
      "Epoch 38: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7647 - accuracy: 0.6935 - val_loss: 0.4896 - val_accuracy: 0.8815\n",
      "Epoch 39/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7657 - accuracy: 0.6886\n",
      "Epoch 39: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7659 - accuracy: 0.6884 - val_loss: 0.4780 - val_accuracy: 0.8824\n",
      "Epoch 40/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.7457 - accuracy: 0.7040\n",
      "Epoch 40: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7515 - accuracy: 0.7008 - val_loss: 0.4688 - val_accuracy: 0.8864\n",
      "Epoch 41/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.6945\n",
      "Epoch 41: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7602 - accuracy: 0.6949 - val_loss: 0.4702 - val_accuracy: 0.8807\n",
      "Epoch 42/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.7426 - accuracy: 0.7086\n",
      "Epoch 42: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7420 - accuracy: 0.7081 - val_loss: 0.4639 - val_accuracy: 0.8920\n",
      "Epoch 43/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7424 - accuracy: 0.7037\n",
      "Epoch 43: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7422 - accuracy: 0.7035 - val_loss: 0.4510 - val_accuracy: 0.8969\n",
      "Epoch 44/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.7134 - accuracy: 0.7134\n",
      "Epoch 44: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7170 - accuracy: 0.7108 - val_loss: 0.4487 - val_accuracy: 0.8944\n",
      "Epoch 45/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7318 - accuracy: 0.7137\n",
      "Epoch 45: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7330 - accuracy: 0.7137 - val_loss: 0.4467 - val_accuracy: 0.8896\n",
      "Epoch 46/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.7289 - accuracy: 0.7109\n",
      "Epoch 46: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7306 - accuracy: 0.7094 - val_loss: 0.4377 - val_accuracy: 0.8928\n",
      "Epoch 47/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.7261 - accuracy: 0.7182\n",
      "Epoch 47: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7264 - accuracy: 0.7164 - val_loss: 0.4303 - val_accuracy: 0.8952\n",
      "Epoch 48/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7267 - accuracy: 0.7151\n",
      "Epoch 48: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7255 - accuracy: 0.7164 - val_loss: 0.4326 - val_accuracy: 0.8920\n",
      "Epoch 49/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.7176 - accuracy: 0.7190\n",
      "Epoch 49: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7152 - accuracy: 0.7212 - val_loss: 0.4211 - val_accuracy: 0.8961\n",
      "Epoch 50/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.7242\n",
      "Epoch 50: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6964 - accuracy: 0.7242 - val_loss: 0.4133 - val_accuracy: 0.9041\n",
      "Epoch 51/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.7050 - accuracy: 0.7194\n",
      "Epoch 51: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7098 - accuracy: 0.7180 - val_loss: 0.4151 - val_accuracy: 0.8952\n",
      "Epoch 52/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.7164 - accuracy: 0.7128\n",
      "Epoch 52: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7168 - accuracy: 0.7124 - val_loss: 0.4147 - val_accuracy: 0.9017\n",
      "Epoch 53/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.7358\n",
      "Epoch 53: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.7358 - val_loss: 0.4099 - val_accuracy: 0.9009\n",
      "Epoch 54/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6808 - accuracy: 0.7309\n",
      "Epoch 54: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6813 - accuracy: 0.7309 - val_loss: 0.4023 - val_accuracy: 0.9041\n",
      "Epoch 55/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.7411\n",
      "Epoch 55: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6731 - accuracy: 0.7411 - val_loss: 0.3978 - val_accuracy: 0.8985\n",
      "Epoch 56/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6756 - accuracy: 0.7370\n",
      "Epoch 56: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6764 - accuracy: 0.7371 - val_loss: 0.3877 - val_accuracy: 0.8985\n",
      "Epoch 57/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6863 - accuracy: 0.7302\n",
      "Epoch 57: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6855 - accuracy: 0.7293 - val_loss: 0.3830 - val_accuracy: 0.9009\n",
      "Epoch 58/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6759 - accuracy: 0.7391\n",
      "Epoch 58: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6753 - accuracy: 0.7376 - val_loss: 0.3913 - val_accuracy: 0.8961\n",
      "Epoch 59/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6732 - accuracy: 0.7374\n",
      "Epoch 59: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6783 - accuracy: 0.7352 - val_loss: 0.3871 - val_accuracy: 0.9065\n",
      "Epoch 60/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6869 - accuracy: 0.7305\n",
      "Epoch 60: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6860 - accuracy: 0.7320 - val_loss: 0.3758 - val_accuracy: 0.9081\n",
      "Epoch 61/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6637 - accuracy: 0.7422\n",
      "Epoch 61: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6630 - accuracy: 0.7425 - val_loss: 0.3768 - val_accuracy: 0.9057\n",
      "Epoch 62/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6705 - accuracy: 0.7422\n",
      "Epoch 62: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6704 - accuracy: 0.7430 - val_loss: 0.3715 - val_accuracy: 0.9081\n",
      "Epoch 63/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6667 - accuracy: 0.7467\n",
      "Epoch 63: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6691 - accuracy: 0.7452 - val_loss: 0.3718 - val_accuracy: 0.9081\n",
      "Epoch 64/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6534 - accuracy: 0.7441\n",
      "Epoch 64: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6524 - accuracy: 0.7444 - val_loss: 0.3752 - val_accuracy: 0.9009\n",
      "Epoch 65/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.7403\n",
      "Epoch 65: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6733 - accuracy: 0.7406 - val_loss: 0.3627 - val_accuracy: 0.9057\n",
      "Epoch 66/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6724 - accuracy: 0.7349\n",
      "Epoch 66: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6709 - accuracy: 0.7358 - val_loss: 0.3637 - val_accuracy: 0.9049\n",
      "Epoch 67/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6508 - accuracy: 0.7497\n",
      "Epoch 67: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6508 - accuracy: 0.7497 - val_loss: 0.3603 - val_accuracy: 0.9081\n",
      "Epoch 68/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6522 - accuracy: 0.7535\n",
      "Epoch 68: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6531 - accuracy: 0.7527 - val_loss: 0.3501 - val_accuracy: 0.9065\n",
      "Epoch 69/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6524 - accuracy: 0.7433\n",
      "Epoch 69: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6547 - accuracy: 0.7401 - val_loss: 0.3580 - val_accuracy: 0.8993\n",
      "Epoch 70/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6415 - accuracy: 0.7535\n",
      "Epoch 70: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6412 - accuracy: 0.7538 - val_loss: 0.3599 - val_accuracy: 0.9073\n",
      "Epoch 71/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6531 - accuracy: 0.7453\n",
      "Epoch 71: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6518 - accuracy: 0.7465 - val_loss: 0.3547 - val_accuracy: 0.9049\n",
      "Epoch 72/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6255 - accuracy: 0.7637\n",
      "Epoch 72: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6260 - accuracy: 0.7634 - val_loss: 0.3429 - val_accuracy: 0.9138\n",
      "Epoch 73/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6440 - accuracy: 0.7532\n",
      "Epoch 73: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6432 - accuracy: 0.7532 - val_loss: 0.3397 - val_accuracy: 0.9098\n",
      "Epoch 74/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6255 - accuracy: 0.7614\n",
      "Epoch 74: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6263 - accuracy: 0.7618 - val_loss: 0.3369 - val_accuracy: 0.9073\n",
      "Epoch 75/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6106 - accuracy: 0.7648\n",
      "Epoch 75: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6102 - accuracy: 0.7669 - val_loss: 0.3405 - val_accuracy: 0.9041\n",
      "Epoch 76/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6341 - accuracy: 0.7605\n",
      "Epoch 76: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6341 - accuracy: 0.7605 - val_loss: 0.3334 - val_accuracy: 0.9081\n",
      "Epoch 77/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6261 - accuracy: 0.7637\n",
      "Epoch 77: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6274 - accuracy: 0.7632 - val_loss: 0.3349 - val_accuracy: 0.9001\n",
      "Epoch 78/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6184 - accuracy: 0.7648\n",
      "Epoch 78: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6184 - accuracy: 0.7642 - val_loss: 0.3324 - val_accuracy: 0.9089\n",
      "Epoch 79/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6265 - accuracy: 0.7581\n",
      "Epoch 79: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6212 - accuracy: 0.7602 - val_loss: 0.3288 - val_accuracy: 0.9146\n",
      "Epoch 80/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.7634\n",
      "Epoch 80: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6251 - accuracy: 0.7634 - val_loss: 0.3243 - val_accuracy: 0.9130\n",
      "Epoch 81/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6488 - accuracy: 0.7443\n",
      "Epoch 81: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6421 - accuracy: 0.7462 - val_loss: 0.3386 - val_accuracy: 0.9146\n",
      "Epoch 82/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6220 - accuracy: 0.7578\n",
      "Epoch 82: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6210 - accuracy: 0.7594 - val_loss: 0.3329 - val_accuracy: 0.9098\n",
      "Epoch 83/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6127 - accuracy: 0.7612\n",
      "Epoch 83: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6144 - accuracy: 0.7594 - val_loss: 0.3321 - val_accuracy: 0.9114\n",
      "Epoch 84/1000\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.6110 - accuracy: 0.7610\n",
      "Epoch 84: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6095 - accuracy: 0.7642 - val_loss: 0.3230 - val_accuracy: 0.9178\n",
      "Epoch 85/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6110 - accuracy: 0.7632\n",
      "Epoch 85: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6133 - accuracy: 0.7624 - val_loss: 0.3244 - val_accuracy: 0.9226\n",
      "Epoch 86/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6163 - accuracy: 0.7713\n",
      "Epoch 86: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6162 - accuracy: 0.7699 - val_loss: 0.3157 - val_accuracy: 0.9178\n",
      "Epoch 87/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6268 - accuracy: 0.7584\n",
      "Epoch 87: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6258 - accuracy: 0.7594 - val_loss: 0.3123 - val_accuracy: 0.9186\n",
      "Epoch 88/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6279 - accuracy: 0.7620\n",
      "Epoch 88: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6250 - accuracy: 0.7632 - val_loss: 0.3242 - val_accuracy: 0.9138\n",
      "Epoch 89/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5950 - accuracy: 0.7705\n",
      "Epoch 89: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5943 - accuracy: 0.7707 - val_loss: 0.3122 - val_accuracy: 0.9234\n",
      "Epoch 90/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6044 - accuracy: 0.7758\n",
      "Epoch 90: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6058 - accuracy: 0.7742 - val_loss: 0.3258 - val_accuracy: 0.9170\n",
      "Epoch 91/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6031 - accuracy: 0.7743\n",
      "Epoch 91: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6003 - accuracy: 0.7753 - val_loss: 0.3110 - val_accuracy: 0.9299\n",
      "Epoch 92/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5950 - accuracy: 0.7772\n",
      "Epoch 92: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5987 - accuracy: 0.7753 - val_loss: 0.3058 - val_accuracy: 0.9347\n",
      "Epoch 93/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.6154 - accuracy: 0.7620\n",
      "Epoch 93: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6077 - accuracy: 0.7637 - val_loss: 0.3113 - val_accuracy: 0.9170\n",
      "Epoch 94/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5695 - accuracy: 0.7816\n",
      "Epoch 94: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5764 - accuracy: 0.7804 - val_loss: 0.3015 - val_accuracy: 0.9234\n",
      "Epoch 95/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6096 - accuracy: 0.7616\n",
      "Epoch 95: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6047 - accuracy: 0.7645 - val_loss: 0.3104 - val_accuracy: 0.9315\n",
      "Epoch 96/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5932 - accuracy: 0.7746\n",
      "Epoch 96: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5919 - accuracy: 0.7772 - val_loss: 0.3108 - val_accuracy: 0.9307\n",
      "Epoch 97/1000\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.5908 - accuracy: 0.7745\n",
      "Epoch 97: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6010 - accuracy: 0.7712 - val_loss: 0.3115 - val_accuracy: 0.9275\n",
      "Epoch 98/1000\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.6021 - accuracy: 0.7781\n",
      "Epoch 98: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5933 - accuracy: 0.7831 - val_loss: 0.3054 - val_accuracy: 0.9259\n",
      "Epoch 99/1000\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.5889 - accuracy: 0.7721\n",
      "Epoch 99: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5830 - accuracy: 0.7745 - val_loss: 0.3030 - val_accuracy: 0.9243\n",
      "Epoch 100/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6052 - accuracy: 0.7743\n",
      "Epoch 100: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5998 - accuracy: 0.7763 - val_loss: 0.3017 - val_accuracy: 0.9243\n",
      "Epoch 101/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5687 - accuracy: 0.7908\n",
      "Epoch 101: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5664 - accuracy: 0.7906 - val_loss: 0.2916 - val_accuracy: 0.9331\n",
      "Epoch 102/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5956 - accuracy: 0.7821\n",
      "Epoch 102: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5948 - accuracy: 0.7833 - val_loss: 0.2998 - val_accuracy: 0.9347\n",
      "Epoch 103/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5812 - accuracy: 0.7803\n",
      "Epoch 103: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5827 - accuracy: 0.7780 - val_loss: 0.3004 - val_accuracy: 0.9234\n",
      "Epoch 104/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5809 - accuracy: 0.7858\n",
      "Epoch 104: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5814 - accuracy: 0.7855 - val_loss: 0.2949 - val_accuracy: 0.9299\n",
      "Epoch 105/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5876 - accuracy: 0.7786\n",
      "Epoch 105: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5878 - accuracy: 0.7785 - val_loss: 0.3014 - val_accuracy: 0.9380\n",
      "Epoch 106/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5903 - accuracy: 0.7775\n",
      "Epoch 106: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5888 - accuracy: 0.7761 - val_loss: 0.2968 - val_accuracy: 0.9412\n",
      "Epoch 107/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5679 - accuracy: 0.7924\n",
      "Epoch 107: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5673 - accuracy: 0.7927 - val_loss: 0.2923 - val_accuracy: 0.9363\n",
      "Epoch 108/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5843 - accuracy: 0.7838\n",
      "Epoch 108: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5835 - accuracy: 0.7844 - val_loss: 0.2919 - val_accuracy: 0.9363\n",
      "Epoch 109/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5927 - accuracy: 0.7775\n",
      "Epoch 109: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5909 - accuracy: 0.7785 - val_loss: 0.2933 - val_accuracy: 0.9371\n",
      "Epoch 110/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5665 - accuracy: 0.7840\n",
      "Epoch 110: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5692 - accuracy: 0.7825 - val_loss: 0.2946 - val_accuracy: 0.9355\n",
      "Epoch 111/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5716 - accuracy: 0.7945\n",
      "Epoch 111: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5732 - accuracy: 0.7938 - val_loss: 0.2824 - val_accuracy: 0.9412\n",
      "Epoch 112/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5840 - accuracy: 0.7893\n",
      "Epoch 112: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5812 - accuracy: 0.7909 - val_loss: 0.3015 - val_accuracy: 0.9315\n",
      "Epoch 113/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5743 - accuracy: 0.7880\n",
      "Epoch 113: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5740 - accuracy: 0.7879 - val_loss: 0.2907 - val_accuracy: 0.9371\n",
      "Epoch 114/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5592 - accuracy: 0.7856\n",
      "Epoch 114: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5553 - accuracy: 0.7871 - val_loss: 0.2899 - val_accuracy: 0.9371\n",
      "Epoch 115/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.6011 - accuracy: 0.7786\n",
      "Epoch 115: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5996 - accuracy: 0.7793 - val_loss: 0.2934 - val_accuracy: 0.9339\n",
      "Epoch 116/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5745 - accuracy: 0.7860\n",
      "Epoch 116: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5756 - accuracy: 0.7860 - val_loss: 0.2878 - val_accuracy: 0.9388\n",
      "Epoch 117/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5710 - accuracy: 0.7963\n",
      "Epoch 117: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5710 - accuracy: 0.7954 - val_loss: 0.2839 - val_accuracy: 0.9380\n",
      "Epoch 118/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7817\n",
      "Epoch 118: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5668 - accuracy: 0.7817 - val_loss: 0.2905 - val_accuracy: 0.9331\n",
      "Epoch 119/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5660 - accuracy: 0.7924\n",
      "Epoch 119: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5676 - accuracy: 0.7917 - val_loss: 0.2842 - val_accuracy: 0.9412\n",
      "Epoch 120/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5691 - accuracy: 0.7879\n",
      "Epoch 120: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5683 - accuracy: 0.7868 - val_loss: 0.2797 - val_accuracy: 0.9452\n",
      "Epoch 121/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5664 - accuracy: 0.7891\n",
      "Epoch 121: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5708 - accuracy: 0.7887 - val_loss: 0.2861 - val_accuracy: 0.9412\n",
      "Epoch 122/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5809 - accuracy: 0.7807\n",
      "Epoch 122: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5814 - accuracy: 0.7798 - val_loss: 0.2844 - val_accuracy: 0.9476\n",
      "Epoch 123/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5735 - accuracy: 0.7855\n",
      "Epoch 123: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5776 - accuracy: 0.7839 - val_loss: 0.2825 - val_accuracy: 0.9428\n",
      "Epoch 124/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5863 - accuracy: 0.7824\n",
      "Epoch 124: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5846 - accuracy: 0.7839 - val_loss: 0.2848 - val_accuracy: 0.9412\n",
      "Epoch 125/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.7898\n",
      "Epoch 125: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5787 - accuracy: 0.7898 - val_loss: 0.2876 - val_accuracy: 0.9404\n",
      "Epoch 126/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5718 - accuracy: 0.7894\n",
      "Epoch 126: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5638 - accuracy: 0.7909 - val_loss: 0.2820 - val_accuracy: 0.9412\n",
      "Epoch 127/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5714 - accuracy: 0.7870\n",
      "Epoch 127: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5700 - accuracy: 0.7876 - val_loss: 0.2746 - val_accuracy: 0.9444\n",
      "Epoch 128/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5605 - accuracy: 0.7958\n",
      "Epoch 128: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5575 - accuracy: 0.7962 - val_loss: 0.2719 - val_accuracy: 0.9428\n",
      "Epoch 129/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5744 - accuracy: 0.7843\n",
      "Epoch 129: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5749 - accuracy: 0.7852 - val_loss: 0.2805 - val_accuracy: 0.9388\n",
      "Epoch 130/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.7976\n",
      "Epoch 130: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5491 - accuracy: 0.7976 - val_loss: 0.2708 - val_accuracy: 0.9452\n",
      "Epoch 131/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5435 - accuracy: 0.7996\n",
      "Epoch 131: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5436 - accuracy: 0.7992 - val_loss: 0.2749 - val_accuracy: 0.9452\n",
      "Epoch 132/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5565 - accuracy: 0.7922\n",
      "Epoch 132: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5559 - accuracy: 0.7938 - val_loss: 0.2695 - val_accuracy: 0.9508\n",
      "Epoch 133/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5527 - accuracy: 0.8015\n",
      "Epoch 133: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.8008 - val_loss: 0.2696 - val_accuracy: 0.9492\n",
      "Epoch 134/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5485 - accuracy: 0.8001\n",
      "Epoch 134: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5498 - accuracy: 0.7997 - val_loss: 0.2662 - val_accuracy: 0.9484\n",
      "Epoch 135/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5605 - accuracy: 0.7905\n",
      "Epoch 135: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5564 - accuracy: 0.7925 - val_loss: 0.2682 - val_accuracy: 0.9468\n",
      "Epoch 136/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5424 - accuracy: 0.7969\n",
      "Epoch 136: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5433 - accuracy: 0.7957 - val_loss: 0.2618 - val_accuracy: 0.9517\n",
      "Epoch 137/1000\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.5734 - accuracy: 0.7829\n",
      "Epoch 137: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5651 - accuracy: 0.7879 - val_loss: 0.2690 - val_accuracy: 0.9452\n",
      "Epoch 138/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5532 - accuracy: 0.7918\n",
      "Epoch 138: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5598 - accuracy: 0.7868 - val_loss: 0.2746 - val_accuracy: 0.9452\n",
      "Epoch 139/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5604 - accuracy: 0.7897\n",
      "Epoch 139: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5566 - accuracy: 0.7922 - val_loss: 0.2746 - val_accuracy: 0.9444\n",
      "Epoch 140/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5365 - accuracy: 0.8072\n",
      "Epoch 140: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5505 - accuracy: 0.8046 - val_loss: 0.2688 - val_accuracy: 0.9460\n",
      "Epoch 141/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5628 - accuracy: 0.7974\n",
      "Epoch 141: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5658 - accuracy: 0.7968 - val_loss: 0.2694 - val_accuracy: 0.9484\n",
      "Epoch 142/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5572 - accuracy: 0.7977\n",
      "Epoch 142: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5553 - accuracy: 0.7989 - val_loss: 0.2717 - val_accuracy: 0.9492\n",
      "Epoch 143/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5549 - accuracy: 0.7951\n",
      "Epoch 143: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5524 - accuracy: 0.7938 - val_loss: 0.2746 - val_accuracy: 0.9460\n",
      "Epoch 144/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5655 - accuracy: 0.7856\n",
      "Epoch 144: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5605 - accuracy: 0.7874 - val_loss: 0.2650 - val_accuracy: 0.9525\n",
      "Epoch 145/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5484 - accuracy: 0.7952\n",
      "Epoch 145: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7960 - val_loss: 0.2732 - val_accuracy: 0.9492\n",
      "Epoch 146/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5328 - accuracy: 0.8066\n",
      "Epoch 146: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5309 - accuracy: 0.8078 - val_loss: 0.2642 - val_accuracy: 0.9508\n",
      "Epoch 147/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5238 - accuracy: 0.8078\n",
      "Epoch 147: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5233 - accuracy: 0.8089 - val_loss: 0.2612 - val_accuracy: 0.9460\n",
      "Epoch 148/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5456 - accuracy: 0.8026\n",
      "Epoch 148: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5474 - accuracy: 0.7981 - val_loss: 0.2619 - val_accuracy: 0.9500\n",
      "Epoch 149/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5353 - accuracy: 0.8011\n",
      "Epoch 149: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5352 - accuracy: 0.8011 - val_loss: 0.2595 - val_accuracy: 0.9541\n",
      "Epoch 150/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5461 - accuracy: 0.8015\n",
      "Epoch 150: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5478 - accuracy: 0.8003 - val_loss: 0.2566 - val_accuracy: 0.9508\n",
      "Epoch 151/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5578 - accuracy: 0.8044\n",
      "Epoch 151: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5659 - accuracy: 0.7997 - val_loss: 0.2680 - val_accuracy: 0.9428\n",
      "Epoch 152/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.8070\n",
      "Epoch 152: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5107 - accuracy: 0.8070 - val_loss: 0.2609 - val_accuracy: 0.9452\n",
      "Epoch 153/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5549 - accuracy: 0.7977\n",
      "Epoch 153: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5522 - accuracy: 0.7976 - val_loss: 0.2674 - val_accuracy: 0.9444\n",
      "Epoch 154/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5228 - accuracy: 0.8106\n",
      "Epoch 154: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5226 - accuracy: 0.8108 - val_loss: 0.2613 - val_accuracy: 0.9460\n",
      "Epoch 155/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5218 - accuracy: 0.8119\n",
      "Epoch 155: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.8140 - val_loss: 0.2664 - val_accuracy: 0.9412\n",
      "Epoch 156/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5306 - accuracy: 0.8047\n",
      "Epoch 156: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5351 - accuracy: 0.8040 - val_loss: 0.2663 - val_accuracy: 0.9380\n",
      "Epoch 157/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5315 - accuracy: 0.8041\n",
      "Epoch 157: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5351 - accuracy: 0.8013 - val_loss: 0.2639 - val_accuracy: 0.9396\n",
      "Epoch 158/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5296 - accuracy: 0.8033\n",
      "Epoch 158: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5295 - accuracy: 0.8027 - val_loss: 0.2657 - val_accuracy: 0.9444\n",
      "Epoch 159/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5359 - accuracy: 0.7977\n",
      "Epoch 159: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5395 - accuracy: 0.7962 - val_loss: 0.2605 - val_accuracy: 0.9468\n",
      "Epoch 160/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5333 - accuracy: 0.8027\n",
      "Epoch 160: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5378 - accuracy: 0.8016 - val_loss: 0.2631 - val_accuracy: 0.9460\n",
      "Epoch 161/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5339 - accuracy: 0.8052\n",
      "Epoch 161: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5324 - accuracy: 0.8062 - val_loss: 0.2628 - val_accuracy: 0.9436\n",
      "Epoch 162/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5105 - accuracy: 0.8069\n",
      "Epoch 162: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5104 - accuracy: 0.8081 - val_loss: 0.2532 - val_accuracy: 0.9460\n",
      "Epoch 163/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.8039\n",
      "Epoch 163: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5408 - accuracy: 0.8038 - val_loss: 0.2520 - val_accuracy: 0.9508\n",
      "Epoch 164/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5427 - accuracy: 0.8011\n",
      "Epoch 164: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5419 - accuracy: 0.8003 - val_loss: 0.2501 - val_accuracy: 0.9500\n",
      "Epoch 165/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5324 - accuracy: 0.8041\n",
      "Epoch 165: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.8046 - val_loss: 0.2639 - val_accuracy: 0.9460\n",
      "Epoch 166/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.8124\n",
      "Epoch 166: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.8124 - val_loss: 0.2561 - val_accuracy: 0.9517\n",
      "Epoch 167/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.8041\n",
      "Epoch 167: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.8043 - val_loss: 0.2597 - val_accuracy: 0.9436\n",
      "Epoch 168/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5036 - accuracy: 0.8098\n",
      "Epoch 168: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5063 - accuracy: 0.8083 - val_loss: 0.2588 - val_accuracy: 0.9404\n",
      "Epoch 169/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5194 - accuracy: 0.8133\n",
      "Epoch 169: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5227 - accuracy: 0.8121 - val_loss: 0.2567 - val_accuracy: 0.9436\n",
      "Epoch 170/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5254 - accuracy: 0.8089\n",
      "Epoch 170: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5277 - accuracy: 0.8067 - val_loss: 0.2563 - val_accuracy: 0.9436\n",
      "Epoch 171/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5430 - accuracy: 0.7996\n",
      "Epoch 171: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5477 - accuracy: 0.7978 - val_loss: 0.2684 - val_accuracy: 0.9452\n",
      "Epoch 172/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.8202\n",
      "Epoch 172: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5088 - accuracy: 0.8202 - val_loss: 0.2557 - val_accuracy: 0.9436\n",
      "Epoch 173/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.5189 - accuracy: 0.8097\n",
      "Epoch 173: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5159 - accuracy: 0.8137 - val_loss: 0.2487 - val_accuracy: 0.9452\n",
      "Epoch 174/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5232 - accuracy: 0.8086\n",
      "Epoch 174: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5231 - accuracy: 0.8091 - val_loss: 0.2547 - val_accuracy: 0.9420\n",
      "Epoch 175/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.8017\n",
      "Epoch 175: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5426 - accuracy: 0.8016 - val_loss: 0.2567 - val_accuracy: 0.9420\n",
      "Epoch 176/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5306 - accuracy: 0.8036\n",
      "Epoch 176: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5305 - accuracy: 0.8038 - val_loss: 0.2522 - val_accuracy: 0.9460\n",
      "Epoch 177/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5151 - accuracy: 0.8099\n",
      "Epoch 177: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5080 - accuracy: 0.8124 - val_loss: 0.2522 - val_accuracy: 0.9468\n",
      "Epoch 178/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8081\n",
      "Epoch 178: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5247 - accuracy: 0.8081 - val_loss: 0.2576 - val_accuracy: 0.9396\n",
      "Epoch 179/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5334 - accuracy: 0.8092\n",
      "Epoch 179: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.8078 - val_loss: 0.2596 - val_accuracy: 0.9460\n",
      "Epoch 180/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5218 - accuracy: 0.8067\n",
      "Epoch 180: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5178 - accuracy: 0.8094 - val_loss: 0.2511 - val_accuracy: 0.9460\n",
      "Epoch 181/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5373 - accuracy: 0.8030\n",
      "Epoch 181: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5388 - accuracy: 0.8027 - val_loss: 0.2431 - val_accuracy: 0.9500\n",
      "Epoch 182/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5253 - accuracy: 0.8108\n",
      "Epoch 182: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5255 - accuracy: 0.8102 - val_loss: 0.2548 - val_accuracy: 0.9492\n",
      "Epoch 183/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8188\n",
      "Epoch 183: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5057 - accuracy: 0.8188 - val_loss: 0.2526 - val_accuracy: 0.9460\n",
      "Epoch 184/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5064 - accuracy: 0.8114\n",
      "Epoch 184: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5058 - accuracy: 0.8118 - val_loss: 0.2449 - val_accuracy: 0.9492\n",
      "Epoch 185/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5332 - accuracy: 0.8095\n",
      "Epoch 185: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5329 - accuracy: 0.8097 - val_loss: 0.2530 - val_accuracy: 0.9500\n",
      "Epoch 186/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5135 - accuracy: 0.8086\n",
      "Epoch 186: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5036 - accuracy: 0.8156 - val_loss: 0.2497 - val_accuracy: 0.9500\n",
      "Epoch 187/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5190 - accuracy: 0.8136\n",
      "Epoch 187: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5193 - accuracy: 0.8134 - val_loss: 0.2483 - val_accuracy: 0.9508\n",
      "Epoch 188/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5184 - accuracy: 0.8114\n",
      "Epoch 188: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5174 - accuracy: 0.8118 - val_loss: 0.2524 - val_accuracy: 0.9484\n",
      "Epoch 189/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5119 - accuracy: 0.8192\n",
      "Epoch 189: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5110 - accuracy: 0.8183 - val_loss: 0.2520 - val_accuracy: 0.9517\n",
      "Epoch 190/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5091 - accuracy: 0.8194\n",
      "Epoch 190: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5170 - accuracy: 0.8172 - val_loss: 0.2426 - val_accuracy: 0.9517\n",
      "Epoch 191/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5113 - accuracy: 0.8177\n",
      "Epoch 191: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5089 - accuracy: 0.8194 - val_loss: 0.2491 - val_accuracy: 0.9484\n",
      "Epoch 192/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5141 - accuracy: 0.8082\n",
      "Epoch 192: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5135 - accuracy: 0.8086 - val_loss: 0.2417 - val_accuracy: 0.9492\n",
      "Epoch 193/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5303 - accuracy: 0.8030\n",
      "Epoch 193: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5327 - accuracy: 0.8024 - val_loss: 0.2596 - val_accuracy: 0.9428\n",
      "Epoch 194/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5083 - accuracy: 0.8125\n",
      "Epoch 194: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5065 - accuracy: 0.8121 - val_loss: 0.2499 - val_accuracy: 0.9517\n",
      "Epoch 195/1000\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.5180 - accuracy: 0.8195\n",
      "Epoch 195: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5201 - accuracy: 0.8167 - val_loss: 0.2671 - val_accuracy: 0.9363\n",
      "Epoch 196/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4986 - accuracy: 0.8247\n",
      "Epoch 196: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4986 - accuracy: 0.8247 - val_loss: 0.2571 - val_accuracy: 0.9460\n",
      "Epoch 197/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5093 - accuracy: 0.8214\n",
      "Epoch 197: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5127 - accuracy: 0.8194 - val_loss: 0.2516 - val_accuracy: 0.9533\n",
      "Epoch 198/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4897 - accuracy: 0.8223\n",
      "Epoch 198: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4930 - accuracy: 0.8204 - val_loss: 0.2434 - val_accuracy: 0.9565\n",
      "Epoch 199/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5219 - accuracy: 0.8094\n",
      "Epoch 199: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5200 - accuracy: 0.8108 - val_loss: 0.2627 - val_accuracy: 0.9380\n",
      "Epoch 200/1000\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.4973 - accuracy: 0.8228\n",
      "Epoch 200: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4985 - accuracy: 0.8226 - val_loss: 0.2509 - val_accuracy: 0.9492\n",
      "Epoch 201/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5155 - accuracy: 0.8080\n",
      "Epoch 201: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8099 - val_loss: 0.2530 - val_accuracy: 0.9452\n",
      "Epoch 202/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5012 - accuracy: 0.8214\n",
      "Epoch 202: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4995 - accuracy: 0.8220 - val_loss: 0.2496 - val_accuracy: 0.9444\n",
      "Epoch 203/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4947 - accuracy: 0.8231\n",
      "Epoch 203: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4906 - accuracy: 0.8245 - val_loss: 0.2426 - val_accuracy: 0.9484\n",
      "Epoch 204/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4941 - accuracy: 0.8142\n",
      "Epoch 204: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.8145 - val_loss: 0.2459 - val_accuracy: 0.9476\n",
      "Epoch 205/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5216 - accuracy: 0.8133\n",
      "Epoch 205: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5162 - accuracy: 0.8153 - val_loss: 0.2464 - val_accuracy: 0.9508\n",
      "Epoch 206/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5031 - accuracy: 0.8157\n",
      "Epoch 206: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5045 - accuracy: 0.8151 - val_loss: 0.2497 - val_accuracy: 0.9460\n",
      "Epoch 207/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5142 - accuracy: 0.8140\n",
      "Epoch 207: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5115 - accuracy: 0.8151 - val_loss: 0.2654 - val_accuracy: 0.9371\n",
      "Epoch 208/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5221 - accuracy: 0.8084\n",
      "Epoch 208: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.8094 - val_loss: 0.2458 - val_accuracy: 0.9492\n",
      "Epoch 209/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5348 - accuracy: 0.8098\n",
      "Epoch 209: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5344 - accuracy: 0.8102 - val_loss: 0.2572 - val_accuracy: 0.9380\n",
      "Epoch 210/1000\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.5115 - accuracy: 0.8133\n",
      "Epoch 210: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5056 - accuracy: 0.8180 - val_loss: 0.2407 - val_accuracy: 0.9533\n",
      "Epoch 211/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.8044\n",
      "Epoch 211: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5426 - accuracy: 0.8040 - val_loss: 0.2556 - val_accuracy: 0.9517\n",
      "Epoch 212/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4962 - accuracy: 0.8142\n",
      "Epoch 212: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4912 - accuracy: 0.8159 - val_loss: 0.2423 - val_accuracy: 0.9541\n",
      "Epoch 213/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5074 - accuracy: 0.8166\n",
      "Epoch 213: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5047 - accuracy: 0.8175 - val_loss: 0.2606 - val_accuracy: 0.9428\n",
      "Epoch 214/1000\n",
      "16/30 [===============>..............] - ETA: 0s - loss: 0.4847 - accuracy: 0.8340\n",
      "Epoch 214: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4906 - accuracy: 0.8293 - val_loss: 0.2551 - val_accuracy: 0.9436\n",
      "Epoch 215/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5026 - accuracy: 0.8200\n",
      "Epoch 215: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5056 - accuracy: 0.8196 - val_loss: 0.2433 - val_accuracy: 0.9468\n",
      "Epoch 216/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5117 - accuracy: 0.8066\n",
      "Epoch 216: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5118 - accuracy: 0.8073 - val_loss: 0.2478 - val_accuracy: 0.9484\n",
      "Epoch 217/1000\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.5111 - accuracy: 0.8180\n",
      "Epoch 217: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5127 - accuracy: 0.8191 - val_loss: 0.2642 - val_accuracy: 0.9371\n",
      "Epoch 218/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5010 - accuracy: 0.8228\n",
      "Epoch 218: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.8218 - val_loss: 0.2497 - val_accuracy: 0.9460\n",
      "Epoch 219/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5184 - accuracy: 0.8036\n",
      "Epoch 219: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8056 - val_loss: 0.2507 - val_accuracy: 0.9436\n",
      "Epoch 220/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.8141\n",
      "Epoch 220: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5181 - accuracy: 0.8145 - val_loss: 0.2572 - val_accuracy: 0.9412\n",
      "Epoch 221/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.4944 - accuracy: 0.8174\n",
      "Epoch 221: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5022 - accuracy: 0.8180 - val_loss: 0.2568 - val_accuracy: 0.9339\n",
      "Epoch 222/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5211 - accuracy: 0.8076\n",
      "Epoch 222: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5207 - accuracy: 0.8078 - val_loss: 0.2537 - val_accuracy: 0.9420\n",
      "Epoch 223/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4932 - accuracy: 0.8222\n",
      "Epoch 223: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4932 - accuracy: 0.8223 - val_loss: 0.2644 - val_accuracy: 0.9363\n",
      "Epoch 224/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4908 - accuracy: 0.8265\n",
      "Epoch 224: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4910 - accuracy: 0.8263 - val_loss: 0.2525 - val_accuracy: 0.9484\n",
      "Epoch 225/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5040 - accuracy: 0.8150\n",
      "Epoch 225: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5056 - accuracy: 0.8140 - val_loss: 0.2594 - val_accuracy: 0.9420\n",
      "Epoch 226/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5256 - accuracy: 0.8087\n",
      "Epoch 226: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5226 - accuracy: 0.8086 - val_loss: 0.2407 - val_accuracy: 0.9605\n",
      "Epoch 227/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5147 - accuracy: 0.8050\n",
      "Epoch 227: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5133 - accuracy: 0.8070 - val_loss: 0.2574 - val_accuracy: 0.9444\n",
      "Epoch 228/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5287 - accuracy: 0.8111\n",
      "Epoch 228: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5284 - accuracy: 0.8113 - val_loss: 0.2602 - val_accuracy: 0.9452\n",
      "Epoch 229/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5006 - accuracy: 0.8241\n",
      "Epoch 229: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5031 - accuracy: 0.8226 - val_loss: 0.2597 - val_accuracy: 0.9371\n",
      "Epoch 230/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5115 - accuracy: 0.8131\n",
      "Epoch 230: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5110 - accuracy: 0.8124 - val_loss: 0.2497 - val_accuracy: 0.9468\n",
      "Epoch 231/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5205 - accuracy: 0.8128\n",
      "Epoch 231: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5200 - accuracy: 0.8116 - val_loss: 0.2624 - val_accuracy: 0.9412\n",
      "Epoch 232/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4877 - accuracy: 0.8189\n",
      "Epoch 232: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4848 - accuracy: 0.8202 - val_loss: 0.2503 - val_accuracy: 0.9404\n",
      "Epoch 233/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5042 - accuracy: 0.8215\n",
      "Epoch 233: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5058 - accuracy: 0.8202 - val_loss: 0.2466 - val_accuracy: 0.9468\n",
      "Epoch 234/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5130 - accuracy: 0.8141\n",
      "Epoch 234: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5130 - accuracy: 0.8140 - val_loss: 0.2606 - val_accuracy: 0.9444\n",
      "Epoch 235/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5263 - accuracy: 0.8108\n",
      "Epoch 235: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5209 - accuracy: 0.8118 - val_loss: 0.2579 - val_accuracy: 0.9468\n",
      "Epoch 236/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5007 - accuracy: 0.8209\n",
      "Epoch 236: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5008 - accuracy: 0.8207 - val_loss: 0.2642 - val_accuracy: 0.9283\n",
      "Epoch 237/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.5072 - accuracy: 0.8137\n",
      "Epoch 237: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5056 - accuracy: 0.8137 - val_loss: 0.2628 - val_accuracy: 0.9339\n",
      "Epoch 238/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4893 - accuracy: 0.8231\n",
      "Epoch 238: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4890 - accuracy: 0.8258 - val_loss: 0.2525 - val_accuracy: 0.9420\n",
      "Epoch 239/1000\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5198 - accuracy: 0.8048\n",
      "Epoch 239: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5198 - accuracy: 0.8048 - val_loss: 0.2810 - val_accuracy: 0.9243\n",
      "Epoch 240/1000\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.4999 - accuracy: 0.8218\n",
      "Epoch 240: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4985 - accuracy: 0.8239 - val_loss: 0.2583 - val_accuracy: 0.9412\n",
      "Epoch 241/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.8279\n",
      "Epoch 241: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4793 - accuracy: 0.8274 - val_loss: 0.2492 - val_accuracy: 0.9468\n",
      "Epoch 242/1000\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.5095 - accuracy: 0.8113\n",
      "Epoch 242: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5153 - accuracy: 0.8065 - val_loss: 0.2514 - val_accuracy: 0.9444\n",
      "Epoch 243/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.5089 - accuracy: 0.8105\n",
      "Epoch 243: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5057 - accuracy: 0.8124 - val_loss: 0.2521 - val_accuracy: 0.9484\n",
      "Epoch 244/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4964 - accuracy: 0.8228\n",
      "Epoch 244: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.8253 - val_loss: 0.2439 - val_accuracy: 0.9500\n",
      "Epoch 245/1000\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.8171\n",
      "Epoch 245: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5209 - accuracy: 0.8164 - val_loss: 0.2528 - val_accuracy: 0.9476\n",
      "Epoch 246/1000\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.4977 - accuracy: 0.8203\n",
      "Epoch 246: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4952 - accuracy: 0.8212 - val_loss: 0.2494 - val_accuracy: 0.9484\n",
      "Epoch 246: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x223b8f83d90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9484\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 283ms/step\n",
      "[3.2724928e-02 5.7822857e-02 8.8852549e-01 1.6308657e-05 2.0910466e-02]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       401\n",
      "           1       0.99      0.87      0.93       383\n",
      "           2       0.89      0.98      0.94       329\n",
      "           3       0.93      1.00      0.96        77\n",
      "           4       1.00      0.94      0.97        51\n",
      "\n",
      "    accuracy                           0.95      1241\n",
      "   macro avg       0.95      0.96      0.95      1241\n",
      "weighted avg       0.95      0.95      0.95      1241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\samma\\AppData\\Local\\Temp\\tmp3p7_upno\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\samma\\AppData\\Local\\Temp\\tmp3p7_upno\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6588"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2724932e-02 5.7822816e-02 8.8852549e-01 1.6308624e-05 2.0910457e-02]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
