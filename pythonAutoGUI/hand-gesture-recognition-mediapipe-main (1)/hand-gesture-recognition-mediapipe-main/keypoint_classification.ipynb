{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                860       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1147 (4.48 KB)\n",
      "Trainable params: 1147 (4.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.8413 - accuracy: 0.2447\n",
      "Epoch 1: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 3s 25ms/step - loss: 1.8362 - accuracy: 0.2466 - val_loss: 1.7079 - val_accuracy: 0.3125\n",
      "Epoch 2/1000\n",
      "13/31 [===========>..................] - ETA: 0s - loss: 1.7121 - accuracy: 0.2951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/31 [=======================>......] - ETA: 0s - loss: 1.6961 - accuracy: 0.2962\n",
      "Epoch 2: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.6810 - accuracy: 0.3010 - val_loss: 1.5702 - val_accuracy: 0.3483\n",
      "Epoch 3/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.5871 - accuracy: 0.3370\n",
      "Epoch 3: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.5877 - accuracy: 0.3360 - val_loss: 1.4741 - val_accuracy: 0.4093\n",
      "Epoch 4/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.5203 - accuracy: 0.3493\n",
      "Epoch 4: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.5185 - accuracy: 0.3495 - val_loss: 1.3977 - val_accuracy: 0.4550\n",
      "Epoch 5/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.4517 - accuracy: 0.3949\n",
      "Epoch 5: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.4513 - accuracy: 0.3973 - val_loss: 1.3334 - val_accuracy: 0.5389\n",
      "Epoch 6/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.4105 - accuracy: 0.4294\n",
      "Epoch 6: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.4059 - accuracy: 0.4296 - val_loss: 1.2782 - val_accuracy: 0.5907\n",
      "Epoch 7/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.3581 - accuracy: 0.4601\n",
      "Epoch 7: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.3585 - accuracy: 0.4614 - val_loss: 1.2182 - val_accuracy: 0.6090\n",
      "Epoch 8/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 1.3413 - accuracy: 0.4676\n",
      "Epoch 8: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.3363 - accuracy: 0.4657 - val_loss: 1.1727 - val_accuracy: 0.6204\n",
      "Epoch 9/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 1.3012 - accuracy: 0.4805\n",
      "Epoch 9: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.2912 - accuracy: 0.4863 - val_loss: 1.1233 - val_accuracy: 0.6585\n",
      "Epoch 10/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.2674 - accuracy: 0.4941\n",
      "Epoch 10: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.2668 - accuracy: 0.4921 - val_loss: 1.0735 - val_accuracy: 0.6799\n",
      "Epoch 11/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.2174 - accuracy: 0.5254\n",
      "Epoch 11: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.2146 - accuracy: 0.5275 - val_loss: 1.0201 - val_accuracy: 0.7515\n",
      "Epoch 12/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.1954 - accuracy: 0.5340\n",
      "Epoch 12: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.1978 - accuracy: 0.5341 - val_loss: 0.9774 - val_accuracy: 0.7607\n",
      "Epoch 13/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.1531 - accuracy: 0.5516\n",
      "Epoch 13: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.1509 - accuracy: 0.5554 - val_loss: 0.9293 - val_accuracy: 0.7668\n",
      "Epoch 14/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 1.1529 - accuracy: 0.5556\n",
      "Epoch 14: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.1418 - accuracy: 0.5590 - val_loss: 0.8912 - val_accuracy: 0.7851\n",
      "Epoch 15/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 1.0979 - accuracy: 0.5773\n",
      "Epoch 15: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.1016 - accuracy: 0.5717 - val_loss: 0.8478 - val_accuracy: 0.7889\n",
      "Epoch 16/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0925 - accuracy: 0.5835\n",
      "Epoch 16: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0935 - accuracy: 0.5834 - val_loss: 0.8124 - val_accuracy: 0.7790\n",
      "Epoch 17/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0854 - accuracy: 0.5905\n",
      "Epoch 17: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.0740 - accuracy: 0.5943 - val_loss: 0.7854 - val_accuracy: 0.8095\n",
      "Epoch 18/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0448 - accuracy: 0.6042\n",
      "Epoch 18: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0468 - accuracy: 0.6037 - val_loss: 0.7494 - val_accuracy: 0.8262\n",
      "Epoch 19/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.0419 - accuracy: 0.6018\n",
      "Epoch 19: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0332 - accuracy: 0.6085 - val_loss: 0.7335 - val_accuracy: 0.8239\n",
      "Epoch 20/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.0362 - accuracy: 0.5991\n",
      "Epoch 20: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.0343 - accuracy: 0.6014 - val_loss: 0.7204 - val_accuracy: 0.8262\n",
      "Epoch 21/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0046 - accuracy: 0.6182\n",
      "Epoch 21: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0048 - accuracy: 0.6172 - val_loss: 0.6930 - val_accuracy: 0.8407\n",
      "Epoch 22/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 1.0005 - accuracy: 0.6182\n",
      "Epoch 22: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9898 - accuracy: 0.6213 - val_loss: 0.6669 - val_accuracy: 0.8514\n",
      "Epoch 23/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 1.0092 - accuracy: 0.6105\n",
      "Epoch 23: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0044 - accuracy: 0.6116 - val_loss: 0.6632 - val_accuracy: 0.8483\n",
      "Epoch 24/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9634 - accuracy: 0.6375\n",
      "Epoch 24: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.9625 - accuracy: 0.6373 - val_loss: 0.6417 - val_accuracy: 0.8422\n",
      "Epoch 25/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.9486 - accuracy: 0.6328\n",
      "Epoch 25: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9508 - accuracy: 0.6329 - val_loss: 0.6204 - val_accuracy: 0.8567\n",
      "Epoch 26/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9427 - accuracy: 0.6451\n",
      "Epoch 26: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.9454 - accuracy: 0.6421 - val_loss: 0.5987 - val_accuracy: 0.8552\n",
      "Epoch 27/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.9462 - accuracy: 0.6484\n",
      "Epoch 27: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.9459 - accuracy: 0.6457 - val_loss: 0.5981 - val_accuracy: 0.8483\n",
      "Epoch 28/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.9240 - accuracy: 0.6476\n",
      "Epoch 28: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9210 - accuracy: 0.6479 - val_loss: 0.5796 - val_accuracy: 0.8590\n",
      "Epoch 29/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.9019 - accuracy: 0.6541\n",
      "Epoch 29: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9039 - accuracy: 0.6551 - val_loss: 0.5679 - val_accuracy: 0.8598\n",
      "Epoch 30/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.9128 - accuracy: 0.6525\n",
      "Epoch 30: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.9130 - accuracy: 0.6518 - val_loss: 0.5525 - val_accuracy: 0.8605\n",
      "Epoch 31/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.9008 - accuracy: 0.6635\n",
      "Epoch 31: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.8956 - accuracy: 0.6655 - val_loss: 0.5445 - val_accuracy: 0.8605\n",
      "Epoch 32/1000\n",
      "17/31 [===============>..............] - ETA: 0s - loss: 0.9465 - accuracy: 0.6411\n",
      "Epoch 32: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9230 - accuracy: 0.6497 - val_loss: 0.5496 - val_accuracy: 0.8552\n",
      "Epoch 33/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.8932 - accuracy: 0.6551\n",
      "Epoch 33: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8916 - accuracy: 0.6553 - val_loss: 0.5391 - val_accuracy: 0.8582\n",
      "Epoch 34/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.8856 - accuracy: 0.6619\n",
      "Epoch 34: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8856 - accuracy: 0.6619 - val_loss: 0.5222 - val_accuracy: 0.8643\n",
      "Epoch 35/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.8495 - accuracy: 0.6747\n",
      "Epoch 35: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.8575 - accuracy: 0.6749 - val_loss: 0.5146 - val_accuracy: 0.8598\n",
      "Epoch 36/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.8662 - accuracy: 0.6677\n",
      "Epoch 36: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8695 - accuracy: 0.6685 - val_loss: 0.5100 - val_accuracy: 0.8620\n",
      "Epoch 37/1000\n",
      "19/31 [=================>............] - ETA: 0s - loss: 0.8493 - accuracy: 0.6768\n",
      "Epoch 37: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.8602 - accuracy: 0.6774 - val_loss: 0.5046 - val_accuracy: 0.8559\n",
      "Epoch 38/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.8625 - accuracy: 0.6761\n",
      "Epoch 38: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8474 - accuracy: 0.6825 - val_loss: 0.4955 - val_accuracy: 0.8697\n",
      "Epoch 39/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.8522 - accuracy: 0.6824\n",
      "Epoch 39: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8525 - accuracy: 0.6797 - val_loss: 0.4883 - val_accuracy: 0.8788\n",
      "Epoch 40/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.8354 - accuracy: 0.6832\n",
      "Epoch 40: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.8365 - accuracy: 0.6815 - val_loss: 0.4813 - val_accuracy: 0.8841\n",
      "Epoch 41/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.8412 - accuracy: 0.6809\n",
      "Epoch 41: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8463 - accuracy: 0.6802 - val_loss: 0.4813 - val_accuracy: 0.8796\n",
      "Epoch 42/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8318 - accuracy: 0.6844\n",
      "Epoch 42: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.8300 - accuracy: 0.6851 - val_loss: 0.4720 - val_accuracy: 0.8780\n",
      "Epoch 43/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.8225 - accuracy: 0.6953\n",
      "Epoch 43: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8238 - accuracy: 0.6945 - val_loss: 0.4709 - val_accuracy: 0.8819\n",
      "Epoch 44/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8133 - accuracy: 0.7047\n",
      "Epoch 44: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.8148 - accuracy: 0.7044 - val_loss: 0.4569 - val_accuracy: 0.8880\n",
      "Epoch 45/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.8028 - accuracy: 0.6972\n",
      "Epoch 45: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7952 - accuracy: 0.7028 - val_loss: 0.4552 - val_accuracy: 0.8880\n",
      "Epoch 46/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7947 - accuracy: 0.7100\n",
      "Epoch 46: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.8020 - accuracy: 0.7046 - val_loss: 0.4497 - val_accuracy: 0.8773\n",
      "Epoch 47/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.8181 - accuracy: 0.6868\n",
      "Epoch 47: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.8205 - accuracy: 0.6889 - val_loss: 0.4500 - val_accuracy: 0.8849\n",
      "Epoch 48/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7879 - accuracy: 0.7035\n",
      "Epoch 48: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7927 - accuracy: 0.7034 - val_loss: 0.4339 - val_accuracy: 0.8887\n",
      "Epoch 49/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7910 - accuracy: 0.7038\n",
      "Epoch 49: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7952 - accuracy: 0.6978 - val_loss: 0.4341 - val_accuracy: 0.8872\n",
      "Epoch 50/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7952 - accuracy: 0.7141\n",
      "Epoch 50: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7940 - accuracy: 0.7117 - val_loss: 0.4304 - val_accuracy: 0.8864\n",
      "Epoch 51/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7929 - accuracy: 0.6956\n",
      "Epoch 51: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.8049 - accuracy: 0.6929 - val_loss: 0.4288 - val_accuracy: 0.8971\n",
      "Epoch 52/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.7918 - accuracy: 0.7081\n",
      "Epoch 52: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7913 - accuracy: 0.7072 - val_loss: 0.4280 - val_accuracy: 0.8941\n",
      "Epoch 53/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7790 - accuracy: 0.7118\n",
      "Epoch 53: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7757 - accuracy: 0.7107 - val_loss: 0.4227 - val_accuracy: 0.8979\n",
      "Epoch 54/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7685 - accuracy: 0.7080\n",
      "Epoch 54: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7686 - accuracy: 0.7110 - val_loss: 0.4089 - val_accuracy: 0.9009\n",
      "Epoch 55/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7731 - accuracy: 0.7123\n",
      "Epoch 55: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.7723 - accuracy: 0.7150 - val_loss: 0.4129 - val_accuracy: 0.8979\n",
      "Epoch 56/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.7877 - accuracy: 0.7035\n",
      "Epoch 56: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7908 - accuracy: 0.7056 - val_loss: 0.4137 - val_accuracy: 0.8895\n",
      "Epoch 57/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7741 - accuracy: 0.7120\n",
      "Epoch 57: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7725 - accuracy: 0.7135 - val_loss: 0.4151 - val_accuracy: 0.9002\n",
      "Epoch 58/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7670 - accuracy: 0.7097\n",
      "Epoch 58: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7717 - accuracy: 0.7087 - val_loss: 0.3995 - val_accuracy: 0.9078\n",
      "Epoch 59/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.7790 - accuracy: 0.7088\n",
      "Epoch 59: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7669 - accuracy: 0.7166 - val_loss: 0.3921 - val_accuracy: 0.9123\n",
      "Epoch 60/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7431 - accuracy: 0.7207\n",
      "Epoch 60: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7468 - accuracy: 0.7194 - val_loss: 0.3941 - val_accuracy: 0.9055\n",
      "Epoch 61/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7702 - accuracy: 0.7083\n",
      "Epoch 61: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7696 - accuracy: 0.7105 - val_loss: 0.3920 - val_accuracy: 0.9047\n",
      "Epoch 62/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7518 - accuracy: 0.7194\n",
      "Epoch 62: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7573 - accuracy: 0.7211 - val_loss: 0.3886 - val_accuracy: 0.9002\n",
      "Epoch 63/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7467 - accuracy: 0.7163\n",
      "Epoch 63: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7479 - accuracy: 0.7148 - val_loss: 0.3841 - val_accuracy: 0.8971\n",
      "Epoch 64/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7406 - accuracy: 0.7135\n",
      "Epoch 64: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7372 - accuracy: 0.7161 - val_loss: 0.3796 - val_accuracy: 0.9040\n",
      "Epoch 65/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7339 - accuracy: 0.7354\n",
      "Epoch 65: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7446 - accuracy: 0.7311 - val_loss: 0.3772 - val_accuracy: 0.9078\n",
      "Epoch 66/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.7482 - accuracy: 0.7235\n",
      "Epoch 66: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.7480 - accuracy: 0.7234 - val_loss: 0.3765 - val_accuracy: 0.9154\n",
      "Epoch 67/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.7224\n",
      "Epoch 67: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.7357 - accuracy: 0.7224 - val_loss: 0.3725 - val_accuracy: 0.9101\n",
      "Epoch 68/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.7474 - accuracy: 0.7124\n",
      "Epoch 68: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7382 - accuracy: 0.7166 - val_loss: 0.3676 - val_accuracy: 0.9162\n",
      "Epoch 69/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7566 - accuracy: 0.7158\n",
      "Epoch 69: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7574 - accuracy: 0.7150 - val_loss: 0.3686 - val_accuracy: 0.9184\n",
      "Epoch 70/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7377 - accuracy: 0.7317\n",
      "Epoch 70: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7261 - accuracy: 0.7372 - val_loss: 0.3600 - val_accuracy: 0.9268\n",
      "Epoch 71/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7080 - accuracy: 0.7246\n",
      "Epoch 71: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7166 - accuracy: 0.7237 - val_loss: 0.3625 - val_accuracy: 0.9139\n",
      "Epoch 72/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7213 - accuracy: 0.7327\n",
      "Epoch 72: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7405 - accuracy: 0.7255 - val_loss: 0.3689 - val_accuracy: 0.9230\n",
      "Epoch 73/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7219 - accuracy: 0.7306\n",
      "Epoch 73: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7339 - accuracy: 0.7344 - val_loss: 0.3647 - val_accuracy: 0.9162\n",
      "Epoch 74/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7310 - accuracy: 0.7302\n",
      "Epoch 74: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7333 - accuracy: 0.7313 - val_loss: 0.3578 - val_accuracy: 0.9200\n",
      "Epoch 75/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7148 - accuracy: 0.7305\n",
      "Epoch 75: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7110 - accuracy: 0.7349 - val_loss: 0.3570 - val_accuracy: 0.9276\n",
      "Epoch 76/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.7430 - accuracy: 0.7173\n",
      "Epoch 76: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7296 - accuracy: 0.7245 - val_loss: 0.3568 - val_accuracy: 0.9314\n",
      "Epoch 77/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7296 - accuracy: 0.7407\n",
      "Epoch 77: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7324 - accuracy: 0.7405 - val_loss: 0.3581 - val_accuracy: 0.9238\n",
      "Epoch 78/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7206 - accuracy: 0.7298\n",
      "Epoch 78: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7227 - accuracy: 0.7278 - val_loss: 0.3558 - val_accuracy: 0.9268\n",
      "Epoch 79/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7168 - accuracy: 0.7283\n",
      "Epoch 79: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7195 - accuracy: 0.7245 - val_loss: 0.3541 - val_accuracy: 0.9261\n",
      "Epoch 80/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6988 - accuracy: 0.7366\n",
      "Epoch 80: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7059 - accuracy: 0.7341 - val_loss: 0.3510 - val_accuracy: 0.9329\n",
      "Epoch 81/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.7264 - accuracy: 0.7335\n",
      "Epoch 81: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7197 - accuracy: 0.7377 - val_loss: 0.3481 - val_accuracy: 0.9352\n",
      "Epoch 82/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7364 - accuracy: 0.7275\n",
      "Epoch 82: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.7315 - accuracy: 0.7311 - val_loss: 0.3463 - val_accuracy: 0.9329\n",
      "Epoch 83/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6958 - accuracy: 0.7447\n",
      "Epoch 83: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7005 - accuracy: 0.7422 - val_loss: 0.3468 - val_accuracy: 0.9383\n",
      "Epoch 84/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7065 - accuracy: 0.7446\n",
      "Epoch 84: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7063 - accuracy: 0.7430 - val_loss: 0.3480 - val_accuracy: 0.9367\n",
      "Epoch 85/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7100 - accuracy: 0.7409\n",
      "Epoch 85: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6972 - accuracy: 0.7468 - val_loss: 0.3457 - val_accuracy: 0.9345\n",
      "Epoch 86/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.7147 - accuracy: 0.7338\n",
      "Epoch 86: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7076 - accuracy: 0.7389 - val_loss: 0.3444 - val_accuracy: 0.9345\n",
      "Epoch 87/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6947 - accuracy: 0.7384\n",
      "Epoch 87: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7077 - accuracy: 0.7308 - val_loss: 0.3474 - val_accuracy: 0.9322\n",
      "Epoch 88/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7069 - accuracy: 0.7389\n",
      "Epoch 88: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.7471 - val_loss: 0.3436 - val_accuracy: 0.9367\n",
      "Epoch 89/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.7000 - accuracy: 0.7446\n",
      "Epoch 89: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6989 - accuracy: 0.7440 - val_loss: 0.3321 - val_accuracy: 0.9375\n",
      "Epoch 90/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6994 - accuracy: 0.7383\n",
      "Epoch 90: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6966 - accuracy: 0.7392 - val_loss: 0.3380 - val_accuracy: 0.9390\n",
      "Epoch 91/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7004 - accuracy: 0.7530\n",
      "Epoch 91: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6944 - accuracy: 0.7542 - val_loss: 0.3364 - val_accuracy: 0.9367\n",
      "Epoch 92/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6814 - accuracy: 0.7624\n",
      "Epoch 92: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6966 - accuracy: 0.7547 - val_loss: 0.3407 - val_accuracy: 0.9383\n",
      "Epoch 93/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7008 - accuracy: 0.7422\n",
      "Epoch 93: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7185 - accuracy: 0.7354 - val_loss: 0.3406 - val_accuracy: 0.9360\n",
      "Epoch 94/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.7402\n",
      "Epoch 94: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6947 - accuracy: 0.7402 - val_loss: 0.3344 - val_accuracy: 0.9360\n",
      "Epoch 95/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6648 - accuracy: 0.7592\n",
      "Epoch 95: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6788 - accuracy: 0.7532 - val_loss: 0.3364 - val_accuracy: 0.9360\n",
      "Epoch 96/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6723 - accuracy: 0.7528\n",
      "Epoch 96: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6634 - accuracy: 0.7562 - val_loss: 0.3180 - val_accuracy: 0.9398\n",
      "Epoch 97/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6822 - accuracy: 0.7557\n",
      "Epoch 97: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6731 - accuracy: 0.7565 - val_loss: 0.3274 - val_accuracy: 0.9390\n",
      "Epoch 98/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6998 - accuracy: 0.7413\n",
      "Epoch 98: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.7463 - val_loss: 0.3259 - val_accuracy: 0.9451\n",
      "Epoch 99/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.7175 - accuracy: 0.7357\n",
      "Epoch 99: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7139 - accuracy: 0.7369 - val_loss: 0.3323 - val_accuracy: 0.9413\n",
      "Epoch 100/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6759 - accuracy: 0.7582\n",
      "Epoch 100: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6751 - accuracy: 0.7575 - val_loss: 0.3216 - val_accuracy: 0.9436\n",
      "Epoch 101/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6751 - accuracy: 0.7524\n",
      "Epoch 101: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6679 - accuracy: 0.7552 - val_loss: 0.3140 - val_accuracy: 0.9428\n",
      "Epoch 102/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6999 - accuracy: 0.7473\n",
      "Epoch 102: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.7037 - accuracy: 0.7445 - val_loss: 0.3203 - val_accuracy: 0.9413\n",
      "Epoch 103/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 0.6700 - accuracy: 0.7504\n",
      "Epoch 103: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6779 - accuracy: 0.7458 - val_loss: 0.3221 - val_accuracy: 0.9451\n",
      "Epoch 104/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6836 - accuracy: 0.7600\n",
      "Epoch 104: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.7613 - val_loss: 0.3218 - val_accuracy: 0.9444\n",
      "Epoch 105/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6740 - accuracy: 0.7493\n",
      "Epoch 105: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6652 - accuracy: 0.7542 - val_loss: 0.3173 - val_accuracy: 0.9428\n",
      "Epoch 106/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6872 - accuracy: 0.7545\n",
      "Epoch 106: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.7544 - val_loss: 0.3230 - val_accuracy: 0.9482\n",
      "Epoch 107/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.7560\n",
      "Epoch 107: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.7560 - val_loss: 0.3227 - val_accuracy: 0.9444\n",
      "Epoch 108/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6654 - accuracy: 0.7639\n",
      "Epoch 108: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6588 - accuracy: 0.7626 - val_loss: 0.3242 - val_accuracy: 0.9383\n",
      "Epoch 109/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6797 - accuracy: 0.7539\n",
      "Epoch 109: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6667 - accuracy: 0.7605 - val_loss: 0.3221 - val_accuracy: 0.9375\n",
      "Epoch 110/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6542 - accuracy: 0.7703\n",
      "Epoch 110: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6606 - accuracy: 0.7677 - val_loss: 0.3090 - val_accuracy: 0.9428\n",
      "Epoch 111/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 0.6928 - accuracy: 0.7426\n",
      "Epoch 111: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.7468 - val_loss: 0.3163 - val_accuracy: 0.9451\n",
      "Epoch 112/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6511 - accuracy: 0.7734\n",
      "Epoch 112: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6468 - accuracy: 0.7738 - val_loss: 0.3186 - val_accuracy: 0.9383\n",
      "Epoch 113/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6787 - accuracy: 0.7546\n",
      "Epoch 113: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6748 - accuracy: 0.7578 - val_loss: 0.3177 - val_accuracy: 0.9428\n",
      "Epoch 114/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.7570\n",
      "Epoch 114: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.7570 - val_loss: 0.3230 - val_accuracy: 0.9421\n",
      "Epoch 115/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.7580\n",
      "Epoch 115: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6625 - accuracy: 0.7580 - val_loss: 0.3228 - val_accuracy: 0.9337\n",
      "Epoch 116/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6673 - accuracy: 0.7593\n",
      "Epoch 116: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6704 - accuracy: 0.7580 - val_loss: 0.3148 - val_accuracy: 0.9436\n",
      "Epoch 117/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6607 - accuracy: 0.7583\n",
      "Epoch 117: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6605 - accuracy: 0.7588 - val_loss: 0.3133 - val_accuracy: 0.9482\n",
      "Epoch 118/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6573 - accuracy: 0.7634\n",
      "Epoch 118: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6550 - accuracy: 0.7616 - val_loss: 0.3204 - val_accuracy: 0.9413\n",
      "Epoch 119/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6411 - accuracy: 0.7713\n",
      "Epoch 119: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6327 - accuracy: 0.7733 - val_loss: 0.3054 - val_accuracy: 0.9489\n",
      "Epoch 120/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 0.7177 - accuracy: 0.7429\n",
      "Epoch 120: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.7463 - val_loss: 0.3206 - val_accuracy: 0.9383\n",
      "Epoch 121/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6469 - accuracy: 0.7659\n",
      "Epoch 121: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6493 - accuracy: 0.7651 - val_loss: 0.3044 - val_accuracy: 0.9383\n",
      "Epoch 122/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6647 - accuracy: 0.7614\n",
      "Epoch 122: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6702 - accuracy: 0.7555 - val_loss: 0.3159 - val_accuracy: 0.9436\n",
      "Epoch 123/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6529 - accuracy: 0.7641\n",
      "Epoch 123: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6639 - accuracy: 0.7598 - val_loss: 0.3126 - val_accuracy: 0.9482\n",
      "Epoch 124/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6477 - accuracy: 0.7697\n",
      "Epoch 124: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6550 - accuracy: 0.7649 - val_loss: 0.3127 - val_accuracy: 0.9466\n",
      "Epoch 125/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6626 - accuracy: 0.7625\n",
      "Epoch 125: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6611 - accuracy: 0.7621 - val_loss: 0.3075 - val_accuracy: 0.9474\n",
      "Epoch 126/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6678 - accuracy: 0.7653\n",
      "Epoch 126: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6570 - accuracy: 0.7641 - val_loss: 0.3086 - val_accuracy: 0.9428\n",
      "Epoch 127/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6544 - accuracy: 0.7734\n",
      "Epoch 127: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6622 - accuracy: 0.7687 - val_loss: 0.3140 - val_accuracy: 0.9405\n",
      "Epoch 128/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6455 - accuracy: 0.7663\n",
      "Epoch 128: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6535 - accuracy: 0.7659 - val_loss: 0.3066 - val_accuracy: 0.9436\n",
      "Epoch 129/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6455 - accuracy: 0.7681\n",
      "Epoch 129: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6475 - accuracy: 0.7677 - val_loss: 0.3137 - val_accuracy: 0.9390\n",
      "Epoch 130/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6492 - accuracy: 0.7666\n",
      "Epoch 130: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6551 - accuracy: 0.7674 - val_loss: 0.3040 - val_accuracy: 0.9512\n",
      "Epoch 131/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6596 - accuracy: 0.7610\n",
      "Epoch 131: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6584 - accuracy: 0.7611 - val_loss: 0.3003 - val_accuracy: 0.9489\n",
      "Epoch 132/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6427 - accuracy: 0.7667\n",
      "Epoch 132: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6524 - accuracy: 0.7644 - val_loss: 0.3114 - val_accuracy: 0.9413\n",
      "Epoch 133/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6535 - accuracy: 0.7637\n",
      "Epoch 133: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6548 - accuracy: 0.7600 - val_loss: 0.3059 - val_accuracy: 0.9451\n",
      "Epoch 134/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6581 - accuracy: 0.7647\n",
      "Epoch 134: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6442 - accuracy: 0.7679 - val_loss: 0.3059 - val_accuracy: 0.9489\n",
      "Epoch 135/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6475 - accuracy: 0.7619\n",
      "Epoch 135: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.7618 - val_loss: 0.3108 - val_accuracy: 0.9482\n",
      "Epoch 136/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6462 - accuracy: 0.7726\n",
      "Epoch 136: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 0.7766 - val_loss: 0.3100 - val_accuracy: 0.9398\n",
      "Epoch 137/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6470 - accuracy: 0.7619\n",
      "Epoch 137: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6595 - accuracy: 0.7560 - val_loss: 0.2997 - val_accuracy: 0.9512\n",
      "Epoch 138/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6533 - accuracy: 0.7663\n",
      "Epoch 138: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.7694 - val_loss: 0.3093 - val_accuracy: 0.9405\n",
      "Epoch 139/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.6406 - accuracy: 0.7714\n",
      "Epoch 139: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6338 - accuracy: 0.7710 - val_loss: 0.2980 - val_accuracy: 0.9520\n",
      "Epoch 140/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6621 - accuracy: 0.7682\n",
      "Epoch 140: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6522 - accuracy: 0.7707 - val_loss: 0.2968 - val_accuracy: 0.9543\n",
      "Epoch 141/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6216 - accuracy: 0.7769\n",
      "Epoch 141: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6303 - accuracy: 0.7748 - val_loss: 0.3004 - val_accuracy: 0.9489\n",
      "Epoch 142/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6505 - accuracy: 0.7627\n",
      "Epoch 142: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6499 - accuracy: 0.7631 - val_loss: 0.3040 - val_accuracy: 0.9535\n",
      "Epoch 143/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6339 - accuracy: 0.7705\n",
      "Epoch 143: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6377 - accuracy: 0.7689 - val_loss: 0.2931 - val_accuracy: 0.9489\n",
      "Epoch 144/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6409 - accuracy: 0.7718\n",
      "Epoch 144: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6350 - accuracy: 0.7753 - val_loss: 0.2885 - val_accuracy: 0.9566\n",
      "Epoch 145/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6723 - accuracy: 0.7632\n",
      "Epoch 145: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6631 - accuracy: 0.7659 - val_loss: 0.3075 - val_accuracy: 0.9459\n",
      "Epoch 146/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6246 - accuracy: 0.7834\n",
      "Epoch 146: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6229 - accuracy: 0.7822 - val_loss: 0.2940 - val_accuracy: 0.9527\n",
      "Epoch 147/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6463 - accuracy: 0.7668\n",
      "Epoch 147: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6463 - accuracy: 0.7692 - val_loss: 0.3064 - val_accuracy: 0.9451\n",
      "Epoch 148/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6104 - accuracy: 0.7766\n",
      "Epoch 148: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6162 - accuracy: 0.7748 - val_loss: 0.2965 - val_accuracy: 0.9550\n",
      "Epoch 149/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6208 - accuracy: 0.7689\n",
      "Epoch 149: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6270 - accuracy: 0.7661 - val_loss: 0.3038 - val_accuracy: 0.9482\n",
      "Epoch 150/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6254 - accuracy: 0.7755\n",
      "Epoch 150: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6245 - accuracy: 0.7766 - val_loss: 0.2994 - val_accuracy: 0.9474\n",
      "Epoch 151/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6436 - accuracy: 0.7737\n",
      "Epoch 151: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6439 - accuracy: 0.7707 - val_loss: 0.3051 - val_accuracy: 0.9466\n",
      "Epoch 152/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6404 - accuracy: 0.7673\n",
      "Epoch 152: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6505 - accuracy: 0.7666 - val_loss: 0.3015 - val_accuracy: 0.9527\n",
      "Epoch 153/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6139 - accuracy: 0.7781\n",
      "Epoch 153: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6247 - accuracy: 0.7778 - val_loss: 0.3022 - val_accuracy: 0.9482\n",
      "Epoch 154/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 0.6536 - accuracy: 0.7731\n",
      "Epoch 154: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6535 - accuracy: 0.7697 - val_loss: 0.2953 - val_accuracy: 0.9535\n",
      "Epoch 155/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6300 - accuracy: 0.7723\n",
      "Epoch 155: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6415 - accuracy: 0.7664 - val_loss: 0.2961 - val_accuracy: 0.9543\n",
      "Epoch 156/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6225 - accuracy: 0.7785\n",
      "Epoch 156: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.7740 - val_loss: 0.2965 - val_accuracy: 0.9550\n",
      "Epoch 157/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6361 - accuracy: 0.7731\n",
      "Epoch 157: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6422 - accuracy: 0.7682 - val_loss: 0.3014 - val_accuracy: 0.9604\n",
      "Epoch 158/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6332 - accuracy: 0.7701\n",
      "Epoch 158: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6297 - accuracy: 0.7717 - val_loss: 0.2995 - val_accuracy: 0.9512\n",
      "Epoch 159/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6164 - accuracy: 0.7720\n",
      "Epoch 159: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6164 - accuracy: 0.7720 - val_loss: 0.2930 - val_accuracy: 0.9558\n",
      "Epoch 160/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6469 - accuracy: 0.7712\n",
      "Epoch 160: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6337 - accuracy: 0.7776 - val_loss: 0.3039 - val_accuracy: 0.9459\n",
      "Epoch 161/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6380 - accuracy: 0.7734\n",
      "Epoch 161: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6361 - accuracy: 0.7738 - val_loss: 0.2950 - val_accuracy: 0.9581\n",
      "Epoch 162/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.7768\n",
      "Epoch 162: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6298 - accuracy: 0.7768 - val_loss: 0.3077 - val_accuracy: 0.9466\n",
      "Epoch 163/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6099 - accuracy: 0.7834\n",
      "Epoch 163: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.7786 - val_loss: 0.3028 - val_accuracy: 0.9489\n",
      "Epoch 164/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6260 - accuracy: 0.7755\n",
      "Epoch 164: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6331 - accuracy: 0.7776 - val_loss: 0.2975 - val_accuracy: 0.9550\n",
      "Epoch 164: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x243fda0fb90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.9550\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 211ms/step\n",
      "[1.6759169e-04 9.9829358e-01 1.3771011e-03 7.6664692e-05 1.2118818e-07\n",
      " 1.6266446e-05 6.8724075e-05]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       413\n",
      "           1       0.96      0.92      0.94       378\n",
      "           2       0.92      0.99      0.95       320\n",
      "           3       1.00      0.97      0.98        88\n",
      "           4       1.00      0.95      0.97        41\n",
      "           5       0.86      1.00      0.92        55\n",
      "           6       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.96      1312\n",
      "   macro avg       0.82      0.83      0.82      1312\n",
      "weighted avg       0.94      0.96      0.95      1312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\samma\\AppData\\Local\\Temp\\tmpssb7fhok\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\samma\\AppData\\Local\\Temp\\tmpssb7fhok\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6676"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6759198e-04 9.9829346e-01 1.3771041e-03 7.6664684e-05 1.2118817e-07\n",
      " 1.6266506e-05 6.8724265e-05]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
