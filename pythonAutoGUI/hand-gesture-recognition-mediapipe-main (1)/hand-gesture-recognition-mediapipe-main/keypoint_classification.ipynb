{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_4 (Dropout)         (None, 42)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                860       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1136 (4.44 KB)\n",
      "Trainable params: 1136 (4.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.7772 - accuracy: 0.2541\n",
      "Epoch 1: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 4s 38ms/step - loss: 1.7606 - accuracy: 0.2625 - val_loss: 1.6728 - val_accuracy: 0.3910\n",
      "Epoch 2/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 1.6998 - accuracy: 0.2578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/31 [=======================>......] - ETA: 0s - loss: 1.6140 - accuracy: 0.3344\n",
      "Epoch 2: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.6013 - accuracy: 0.3352 - val_loss: 1.5066 - val_accuracy: 0.3344\n",
      "Epoch 3/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 1.5054 - accuracy: 0.3529\n",
      "Epoch 3: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 1.4984 - accuracy: 0.3551 - val_loss: 1.3919 - val_accuracy: 0.4042\n",
      "Epoch 4/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 1.4384 - accuracy: 0.3877\n",
      "Epoch 4: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.4396 - accuracy: 0.3854 - val_loss: 1.3160 - val_accuracy: 0.4554\n",
      "Epoch 5/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.3938 - accuracy: 0.3957\n",
      "Epoch 5: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.3931 - accuracy: 0.3971 - val_loss: 1.2598 - val_accuracy: 0.5229\n",
      "Epoch 6/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 1.3407 - accuracy: 0.4216\n",
      "Epoch 6: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.3370 - accuracy: 0.4247 - val_loss: 1.2029 - val_accuracy: 0.5283\n",
      "Epoch 7/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.2997 - accuracy: 0.4434\n",
      "Epoch 7: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.3045 - accuracy: 0.4444 - val_loss: 1.1522 - val_accuracy: 0.5981\n",
      "Epoch 8/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.2634 - accuracy: 0.4938\n",
      "Epoch 8: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.2663 - accuracy: 0.4881 - val_loss: 1.1023 - val_accuracy: 0.6416\n",
      "Epoch 9/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.2597 - accuracy: 0.4822\n",
      "Epoch 9: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.2571 - accuracy: 0.4829 - val_loss: 1.0632 - val_accuracy: 0.6827\n",
      "Epoch 10/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 1.2171 - accuracy: 0.5029\n",
      "Epoch 10: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.2165 - accuracy: 0.5039 - val_loss: 1.0129 - val_accuracy: 0.7013\n",
      "Epoch 11/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 1.1930 - accuracy: 0.5226\n",
      "Epoch 11: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 1.1877 - accuracy: 0.5264 - val_loss: 0.9702 - val_accuracy: 0.7036\n",
      "Epoch 12/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.1504 - accuracy: 0.5453\n",
      "Epoch 12: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.1513 - accuracy: 0.5424 - val_loss: 0.9283 - val_accuracy: 0.7269\n",
      "Epoch 13/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.1256 - accuracy: 0.5428\n",
      "Epoch 13: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.1250 - accuracy: 0.5404 - val_loss: 0.8895 - val_accuracy: 0.7277\n",
      "Epoch 14/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 1.1154 - accuracy: 0.5454\n",
      "Epoch 14: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.1178 - accuracy: 0.5476 - val_loss: 0.8586 - val_accuracy: 0.7541\n",
      "Epoch 15/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 1.0912 - accuracy: 0.5559\n",
      "Epoch 15: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.0850 - accuracy: 0.5566 - val_loss: 0.8290 - val_accuracy: 0.7882\n",
      "Epoch 16/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0487 - accuracy: 0.5760\n",
      "Epoch 16: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.0488 - accuracy: 0.5758 - val_loss: 0.7825 - val_accuracy: 0.7944\n",
      "Epoch 17/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 1.0274 - accuracy: 0.5840\n",
      "Epoch 17: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.0335 - accuracy: 0.5825 - val_loss: 0.7479 - val_accuracy: 0.8192\n",
      "Epoch 18/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.0158 - accuracy: 0.5831\n",
      "Epoch 18: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 1.0144 - accuracy: 0.5874 - val_loss: 0.7206 - val_accuracy: 0.8324\n",
      "Epoch 19/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.9909 - accuracy: 0.6013\n",
      "Epoch 19: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.9906 - accuracy: 0.6024 - val_loss: 0.6988 - val_accuracy: 0.8371\n",
      "Epoch 20/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.9864 - accuracy: 0.6029\n",
      "Epoch 20: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.9768 - accuracy: 0.6061 - val_loss: 0.6797 - val_accuracy: 0.8386\n",
      "Epoch 21/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.9630 - accuracy: 0.6107\n",
      "Epoch 21: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9648 - accuracy: 0.6110 - val_loss: 0.6547 - val_accuracy: 0.8363\n",
      "Epoch 22/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.9300 - accuracy: 0.6367\n",
      "Epoch 22: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.9411 - accuracy: 0.6301 - val_loss: 0.6332 - val_accuracy: 0.8425\n",
      "Epoch 23/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.9325 - accuracy: 0.6305\n",
      "Epoch 23: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.9334 - accuracy: 0.6304 - val_loss: 0.6179 - val_accuracy: 0.8472\n",
      "Epoch 24/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.9098 - accuracy: 0.6386\n",
      "Epoch 24: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9057 - accuracy: 0.6410 - val_loss: 0.5973 - val_accuracy: 0.8534\n",
      "Epoch 25/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.8930 - accuracy: 0.6395\n",
      "Epoch 25: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8959 - accuracy: 0.6389 - val_loss: 0.5788 - val_accuracy: 0.8534\n",
      "Epoch 26/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.8876 - accuracy: 0.6392\n",
      "Epoch 26: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8848 - accuracy: 0.6394 - val_loss: 0.5638 - val_accuracy: 0.8673\n",
      "Epoch 27/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.8792 - accuracy: 0.6380\n",
      "Epoch 27: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8782 - accuracy: 0.6392 - val_loss: 0.5543 - val_accuracy: 0.8681\n",
      "Epoch 28/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.8767 - accuracy: 0.6539\n",
      "Epoch 28: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8738 - accuracy: 0.6557 - val_loss: 0.5418 - val_accuracy: 0.8697\n",
      "Epoch 29/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.8547 - accuracy: 0.6550\n",
      "Epoch 29: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8511 - accuracy: 0.6591 - val_loss: 0.5261 - val_accuracy: 0.8681\n",
      "Epoch 30/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.8395 - accuracy: 0.6689\n",
      "Epoch 30: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8434 - accuracy: 0.6650 - val_loss: 0.5095 - val_accuracy: 0.8929\n",
      "Epoch 31/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.8404 - accuracy: 0.6649\n",
      "Epoch 31: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8439 - accuracy: 0.6632 - val_loss: 0.5124 - val_accuracy: 0.8898\n",
      "Epoch 32/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.8383 - accuracy: 0.6595\n",
      "Epoch 32: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8341 - accuracy: 0.6653 - val_loss: 0.4983 - val_accuracy: 0.8945\n",
      "Epoch 33/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.8511 - accuracy: 0.6534\n",
      "Epoch 33: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8487 - accuracy: 0.6557 - val_loss: 0.4920 - val_accuracy: 0.8984\n",
      "Epoch 34/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.8090 - accuracy: 0.6739\n",
      "Epoch 34: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8113 - accuracy: 0.6741 - val_loss: 0.4828 - val_accuracy: 0.8976\n",
      "Epoch 35/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.8141 - accuracy: 0.6807\n",
      "Epoch 35: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.8082 - accuracy: 0.6829 - val_loss: 0.4682 - val_accuracy: 0.8968\n",
      "Epoch 36/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.8017 - accuracy: 0.6710\n",
      "Epoch 36: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8057 - accuracy: 0.6710 - val_loss: 0.4624 - val_accuracy: 0.9038\n",
      "Epoch 37/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.7916 - accuracy: 0.6785\n",
      "Epoch 37: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8018 - accuracy: 0.6756 - val_loss: 0.4510 - val_accuracy: 0.9147\n",
      "Epoch 38/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8286 - accuracy: 0.6786\n",
      "Epoch 38: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.8284 - accuracy: 0.6787 - val_loss: 0.4522 - val_accuracy: 0.9100\n",
      "Epoch 39/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.7813 - accuracy: 0.6956\n",
      "Epoch 39: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7808 - accuracy: 0.6943 - val_loss: 0.4444 - val_accuracy: 0.9139\n",
      "Epoch 40/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.8057 - accuracy: 0.6854\n",
      "Epoch 40: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7931 - accuracy: 0.6924 - val_loss: 0.4399 - val_accuracy: 0.9077\n",
      "Epoch 41/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7698 - accuracy: 0.6953\n",
      "Epoch 41: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7735 - accuracy: 0.6930 - val_loss: 0.4281 - val_accuracy: 0.9131\n",
      "Epoch 42/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.7621 - accuracy: 0.7076\n",
      "Epoch 42: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7559 - accuracy: 0.7087 - val_loss: 0.4236 - val_accuracy: 0.9170\n",
      "Epoch 43/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7677 - accuracy: 0.6994\n",
      "Epoch 43: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7671 - accuracy: 0.6979 - val_loss: 0.4198 - val_accuracy: 0.9131\n",
      "Epoch 44/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7503 - accuracy: 0.7073\n",
      "Epoch 44: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7527 - accuracy: 0.7054 - val_loss: 0.4070 - val_accuracy: 0.9209\n",
      "Epoch 45/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.7557 - accuracy: 0.7017\n",
      "Epoch 45: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7589 - accuracy: 0.7018 - val_loss: 0.4110 - val_accuracy: 0.9240\n",
      "Epoch 46/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.7322 - accuracy: 0.7121\n",
      "Epoch 46: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7353 - accuracy: 0.7129 - val_loss: 0.4041 - val_accuracy: 0.9279\n",
      "Epoch 47/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7526 - accuracy: 0.7022\n",
      "Epoch 47: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7558 - accuracy: 0.6999 - val_loss: 0.4004 - val_accuracy: 0.9255\n",
      "Epoch 48/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7441 - accuracy: 0.7078\n",
      "Epoch 48: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7452 - accuracy: 0.7067 - val_loss: 0.3946 - val_accuracy: 0.9240\n",
      "Epoch 49/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.7465 - accuracy: 0.7146\n",
      "Epoch 49: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.7408 - accuracy: 0.7155 - val_loss: 0.3896 - val_accuracy: 0.9286\n",
      "Epoch 50/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7320 - accuracy: 0.7117\n",
      "Epoch 50: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.7327 - accuracy: 0.7103 - val_loss: 0.3857 - val_accuracy: 0.9364\n",
      "Epoch 51/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7435 - accuracy: 0.7103\n",
      "Epoch 51: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7431 - accuracy: 0.7098 - val_loss: 0.3839 - val_accuracy: 0.9294\n",
      "Epoch 52/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7308 - accuracy: 0.7131\n",
      "Epoch 52: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7269 - accuracy: 0.7142 - val_loss: 0.3732 - val_accuracy: 0.9418\n",
      "Epoch 53/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7466 - accuracy: 0.7072\n",
      "Epoch 53: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.7481 - accuracy: 0.7067 - val_loss: 0.3716 - val_accuracy: 0.9372\n",
      "Epoch 54/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6949 - accuracy: 0.7289\n",
      "Epoch 54: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6961 - accuracy: 0.7302 - val_loss: 0.3670 - val_accuracy: 0.9434\n",
      "Epoch 55/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7266 - accuracy: 0.7150\n",
      "Epoch 55: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7321 - accuracy: 0.7144 - val_loss: 0.3670 - val_accuracy: 0.9472\n",
      "Epoch 56/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7227 - accuracy: 0.7193\n",
      "Epoch 56: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7224 - accuracy: 0.7201 - val_loss: 0.3641 - val_accuracy: 0.9395\n",
      "Epoch 57/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7150 - accuracy: 0.7212\n",
      "Epoch 57: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.7154 - accuracy: 0.7222 - val_loss: 0.3620 - val_accuracy: 0.9441\n",
      "Epoch 58/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.7328 - accuracy: 0.7144\n",
      "Epoch 58: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.7377 - accuracy: 0.7121 - val_loss: 0.3601 - val_accuracy: 0.9480\n",
      "Epoch 59/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7093 - accuracy: 0.7320\n",
      "Epoch 59: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7093 - accuracy: 0.7323 - val_loss: 0.3511 - val_accuracy: 0.9558\n",
      "Epoch 60/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.7133 - accuracy: 0.7302\n",
      "Epoch 60: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7233 - accuracy: 0.7253 - val_loss: 0.3543 - val_accuracy: 0.9488\n",
      "Epoch 61/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.7152 - accuracy: 0.7287\n",
      "Epoch 61: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.7183 - accuracy: 0.7294 - val_loss: 0.3468 - val_accuracy: 0.9457\n",
      "Epoch 62/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.7087 - accuracy: 0.7231\n",
      "Epoch 62: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7109 - accuracy: 0.7214 - val_loss: 0.3511 - val_accuracy: 0.9488\n",
      "Epoch 63/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.7311\n",
      "Epoch 63: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6949 - accuracy: 0.7305 - val_loss: 0.3441 - val_accuracy: 0.9519\n",
      "Epoch 64/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7189 - accuracy: 0.7292\n",
      "Epoch 64: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7188 - accuracy: 0.7294 - val_loss: 0.3374 - val_accuracy: 0.9496\n",
      "Epoch 65/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6856 - accuracy: 0.7395\n",
      "Epoch 65: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6848 - accuracy: 0.7403 - val_loss: 0.3384 - val_accuracy: 0.9550\n",
      "Epoch 66/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6893 - accuracy: 0.7396\n",
      "Epoch 66: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6875 - accuracy: 0.7408 - val_loss: 0.3355 - val_accuracy: 0.9457\n",
      "Epoch 67/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6914 - accuracy: 0.7439\n",
      "Epoch 67: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6900 - accuracy: 0.7447 - val_loss: 0.3217 - val_accuracy: 0.9612\n",
      "Epoch 68/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6827 - accuracy: 0.7355\n",
      "Epoch 68: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6865 - accuracy: 0.7356 - val_loss: 0.3270 - val_accuracy: 0.9566\n",
      "Epoch 69/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6943 - accuracy: 0.7367\n",
      "Epoch 69: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6970 - accuracy: 0.7331 - val_loss: 0.3256 - val_accuracy: 0.9527\n",
      "Epoch 70/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6687 - accuracy: 0.7444\n",
      "Epoch 70: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6683 - accuracy: 0.7447 - val_loss: 0.3213 - val_accuracy: 0.9550\n",
      "Epoch 71/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6900 - accuracy: 0.7422\n",
      "Epoch 71: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6881 - accuracy: 0.7439 - val_loss: 0.3191 - val_accuracy: 0.9348\n",
      "Epoch 72/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6814 - accuracy: 0.7430\n",
      "Epoch 72: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6825 - accuracy: 0.7426 - val_loss: 0.3188 - val_accuracy: 0.9488\n",
      "Epoch 73/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 0.6834 - accuracy: 0.7437\n",
      "Epoch 73: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6799 - accuracy: 0.7468 - val_loss: 0.3186 - val_accuracy: 0.9496\n",
      "Epoch 74/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6753 - accuracy: 0.7387\n",
      "Epoch 74: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6737 - accuracy: 0.7367 - val_loss: 0.3136 - val_accuracy: 0.9519\n",
      "Epoch 75/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6760 - accuracy: 0.7456\n",
      "Epoch 75: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6750 - accuracy: 0.7465 - val_loss: 0.3086 - val_accuracy: 0.9573\n",
      "Epoch 76/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6812 - accuracy: 0.7403\n",
      "Epoch 76: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6811 - accuracy: 0.7385 - val_loss: 0.3083 - val_accuracy: 0.9511\n",
      "Epoch 77/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6388 - accuracy: 0.7619\n",
      "Epoch 77: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6434 - accuracy: 0.7597 - val_loss: 0.3068 - val_accuracy: 0.9527\n",
      "Epoch 78/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6573 - accuracy: 0.7471\n",
      "Epoch 78: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6594 - accuracy: 0.7468 - val_loss: 0.3013 - val_accuracy: 0.9566\n",
      "Epoch 79/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6793 - accuracy: 0.7492\n",
      "Epoch 79: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6771 - accuracy: 0.7504 - val_loss: 0.3084 - val_accuracy: 0.9558\n",
      "Epoch 80/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6676 - accuracy: 0.7486\n",
      "Epoch 80: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6623 - accuracy: 0.7499 - val_loss: 0.3039 - val_accuracy: 0.9542\n",
      "Epoch 81/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6690 - accuracy: 0.7454\n",
      "Epoch 81: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6687 - accuracy: 0.7473 - val_loss: 0.2992 - val_accuracy: 0.9597\n",
      "Epoch 82/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6690 - accuracy: 0.7462\n",
      "Epoch 82: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6649 - accuracy: 0.7504 - val_loss: 0.2987 - val_accuracy: 0.9527\n",
      "Epoch 83/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6507 - accuracy: 0.7616\n",
      "Epoch 83: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6560 - accuracy: 0.7587 - val_loss: 0.2949 - val_accuracy: 0.9542\n",
      "Epoch 84/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6650 - accuracy: 0.7489\n",
      "Epoch 84: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6629 - accuracy: 0.7501 - val_loss: 0.3027 - val_accuracy: 0.9566\n",
      "Epoch 85/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6583 - accuracy: 0.7494\n",
      "Epoch 85: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6574 - accuracy: 0.7496 - val_loss: 0.2973 - val_accuracy: 0.9465\n",
      "Epoch 86/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6611 - accuracy: 0.7514\n",
      "Epoch 86: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6584 - accuracy: 0.7535 - val_loss: 0.2966 - val_accuracy: 0.9581\n",
      "Epoch 87/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6718 - accuracy: 0.7494\n",
      "Epoch 87: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6706 - accuracy: 0.7519 - val_loss: 0.2955 - val_accuracy: 0.9496\n",
      "Epoch 88/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6607 - accuracy: 0.7589\n",
      "Epoch 88: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6607 - accuracy: 0.7589 - val_loss: 0.2942 - val_accuracy: 0.9426\n",
      "Epoch 89/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6633 - accuracy: 0.7487\n",
      "Epoch 89: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6620 - accuracy: 0.7491 - val_loss: 0.2899 - val_accuracy: 0.9612\n",
      "Epoch 90/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6557 - accuracy: 0.7545\n",
      "Epoch 90: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6611 - accuracy: 0.7538 - val_loss: 0.2914 - val_accuracy: 0.9597\n",
      "Epoch 91/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7623\n",
      "Epoch 91: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6445 - accuracy: 0.7623 - val_loss: 0.2863 - val_accuracy: 0.9535\n",
      "Epoch 92/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6458 - accuracy: 0.7584\n",
      "Epoch 92: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6505 - accuracy: 0.7566 - val_loss: 0.2827 - val_accuracy: 0.9620\n",
      "Epoch 93/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6421 - accuracy: 0.7561\n",
      "Epoch 93: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.7558 - val_loss: 0.2859 - val_accuracy: 0.9597\n",
      "Epoch 94/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6570 - accuracy: 0.7539\n",
      "Epoch 94: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6515 - accuracy: 0.7574 - val_loss: 0.2858 - val_accuracy: 0.9573\n",
      "Epoch 95/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6392 - accuracy: 0.7606\n",
      "Epoch 95: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6409 - accuracy: 0.7584 - val_loss: 0.2811 - val_accuracy: 0.9620\n",
      "Epoch 96/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6430 - accuracy: 0.7522\n",
      "Epoch 96: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6427 - accuracy: 0.7504 - val_loss: 0.2815 - val_accuracy: 0.9573\n",
      "Epoch 97/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6399 - accuracy: 0.7630\n",
      "Epoch 97: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6391 - accuracy: 0.7636 - val_loss: 0.2717 - val_accuracy: 0.9651\n",
      "Epoch 98/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6297 - accuracy: 0.7699\n",
      "Epoch 98: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.7677 - val_loss: 0.2747 - val_accuracy: 0.9597\n",
      "Epoch 99/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6419 - accuracy: 0.7731\n",
      "Epoch 99: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6340 - accuracy: 0.7750 - val_loss: 0.2729 - val_accuracy: 0.9597\n",
      "Epoch 100/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6373 - accuracy: 0.7613\n",
      "Epoch 100: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6359 - accuracy: 0.7597 - val_loss: 0.2763 - val_accuracy: 0.9597\n",
      "Epoch 101/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6427 - accuracy: 0.7621\n",
      "Epoch 101: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.7607 - val_loss: 0.2776 - val_accuracy: 0.9612\n",
      "Epoch 102/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6229 - accuracy: 0.7617\n",
      "Epoch 102: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6225 - accuracy: 0.7649 - val_loss: 0.2734 - val_accuracy: 0.9643\n",
      "Epoch 103/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6157 - accuracy: 0.7704\n",
      "Epoch 103: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6223 - accuracy: 0.7656 - val_loss: 0.2642 - val_accuracy: 0.9690\n",
      "Epoch 104/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6373 - accuracy: 0.7674\n",
      "Epoch 104: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.7675 - val_loss: 0.2642 - val_accuracy: 0.9659\n",
      "Epoch 105/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6454 - accuracy: 0.7605\n",
      "Epoch 105: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.7644 - val_loss: 0.2598 - val_accuracy: 0.9728\n",
      "Epoch 106/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6453 - accuracy: 0.7589\n",
      "Epoch 106: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6464 - accuracy: 0.7594 - val_loss: 0.2688 - val_accuracy: 0.9697\n",
      "Epoch 107/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6452 - accuracy: 0.7614\n",
      "Epoch 107: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.7594 - val_loss: 0.2718 - val_accuracy: 0.9651\n",
      "Epoch 108/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6298 - accuracy: 0.7692\n",
      "Epoch 108: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6365 - accuracy: 0.7656 - val_loss: 0.2658 - val_accuracy: 0.9736\n",
      "Epoch 109/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6422 - accuracy: 0.7581\n",
      "Epoch 109: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6452 - accuracy: 0.7574 - val_loss: 0.2604 - val_accuracy: 0.9674\n",
      "Epoch 110/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6230 - accuracy: 0.7584\n",
      "Epoch 110: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6267 - accuracy: 0.7558 - val_loss: 0.2606 - val_accuracy: 0.9674\n",
      "Epoch 111/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6394 - accuracy: 0.7672\n",
      "Epoch 111: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6503 - accuracy: 0.7649 - val_loss: 0.2619 - val_accuracy: 0.9666\n",
      "Epoch 112/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6435 - accuracy: 0.7560\n",
      "Epoch 112: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6433 - accuracy: 0.7561 - val_loss: 0.2652 - val_accuracy: 0.9666\n",
      "Epoch 113/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6204 - accuracy: 0.7751\n",
      "Epoch 113: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.7726 - val_loss: 0.2605 - val_accuracy: 0.9713\n",
      "Epoch 114/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6419 - accuracy: 0.7567\n",
      "Epoch 114: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6454 - accuracy: 0.7545 - val_loss: 0.2636 - val_accuracy: 0.9620\n",
      "Epoch 115/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6280 - accuracy: 0.7746\n",
      "Epoch 115: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6266 - accuracy: 0.7739 - val_loss: 0.2618 - val_accuracy: 0.9659\n",
      "Epoch 116/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.7661\n",
      "Epoch 116: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6315 - accuracy: 0.7659 - val_loss: 0.2646 - val_accuracy: 0.9643\n",
      "Epoch 117/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6527 - accuracy: 0.7609\n",
      "Epoch 117: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.7613 - val_loss: 0.2661 - val_accuracy: 0.9651\n",
      "Epoch 118/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6333 - accuracy: 0.7689\n",
      "Epoch 118: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6397 - accuracy: 0.7667 - val_loss: 0.2624 - val_accuracy: 0.9674\n",
      "Epoch 119/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6229 - accuracy: 0.7662\n",
      "Epoch 119: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6251 - accuracy: 0.7659 - val_loss: 0.2607 - val_accuracy: 0.9589\n",
      "Epoch 120/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6333 - accuracy: 0.7590\n",
      "Epoch 120: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6349 - accuracy: 0.7594 - val_loss: 0.2635 - val_accuracy: 0.9682\n",
      "Epoch 121/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6357 - accuracy: 0.7651\n",
      "Epoch 121: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.7641 - val_loss: 0.2642 - val_accuracy: 0.9705\n",
      "Epoch 122/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6170 - accuracy: 0.7731\n",
      "Epoch 122: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6175 - accuracy: 0.7734 - val_loss: 0.2557 - val_accuracy: 0.9690\n",
      "Epoch 123/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6317 - accuracy: 0.7734\n",
      "Epoch 123: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6282 - accuracy: 0.7744 - val_loss: 0.2605 - val_accuracy: 0.9635\n",
      "Epoch 124/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6442 - accuracy: 0.7661\n",
      "Epoch 124: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.7659 - val_loss: 0.2570 - val_accuracy: 0.9697\n",
      "Epoch 125/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6221 - accuracy: 0.7721\n",
      "Epoch 125: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6203 - accuracy: 0.7732 - val_loss: 0.2585 - val_accuracy: 0.9674\n",
      "Epoch 126/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6092 - accuracy: 0.7767\n",
      "Epoch 126: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.7724 - val_loss: 0.2507 - val_accuracy: 0.9682\n",
      "Epoch 127/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6157 - accuracy: 0.7746\n",
      "Epoch 127: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6173 - accuracy: 0.7747 - val_loss: 0.2490 - val_accuracy: 0.9736\n",
      "Epoch 128/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6110 - accuracy: 0.7710\n",
      "Epoch 128: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6174 - accuracy: 0.7724 - val_loss: 0.2477 - val_accuracy: 0.9705\n",
      "Epoch 129/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6179 - accuracy: 0.7714\n",
      "Epoch 129: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6170 - accuracy: 0.7719 - val_loss: 0.2486 - val_accuracy: 0.9690\n",
      "Epoch 130/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6272 - accuracy: 0.7648\n",
      "Epoch 130: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6268 - accuracy: 0.7651 - val_loss: 0.2523 - val_accuracy: 0.9721\n",
      "Epoch 131/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6243 - accuracy: 0.7651\n",
      "Epoch 131: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6249 - accuracy: 0.7641 - val_loss: 0.2529 - val_accuracy: 0.9690\n",
      "Epoch 132/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.5884 - accuracy: 0.7797\n",
      "Epoch 132: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5883 - accuracy: 0.7770 - val_loss: 0.2505 - val_accuracy: 0.9713\n",
      "Epoch 133/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6327 - accuracy: 0.7625\n",
      "Epoch 133: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6363 - accuracy: 0.7625 - val_loss: 0.2540 - val_accuracy: 0.9690\n",
      "Epoch 134/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6180 - accuracy: 0.7790\n",
      "Epoch 134: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6174 - accuracy: 0.7765 - val_loss: 0.2462 - val_accuracy: 0.9744\n",
      "Epoch 135/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6021 - accuracy: 0.7834\n",
      "Epoch 135: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6139 - accuracy: 0.7760 - val_loss: 0.2470 - val_accuracy: 0.9705\n",
      "Epoch 136/1000\n",
      "17/31 [===============>..............] - ETA: 0s - loss: 0.5966 - accuracy: 0.7803\n",
      "Epoch 136: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.7703 - val_loss: 0.2488 - val_accuracy: 0.9721\n",
      "Epoch 137/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6299 - accuracy: 0.7764\n",
      "Epoch 137: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6331 - accuracy: 0.7755 - val_loss: 0.2558 - val_accuracy: 0.9659\n",
      "Epoch 138/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5955 - accuracy: 0.7768\n",
      "Epoch 138: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5963 - accuracy: 0.7763 - val_loss: 0.2483 - val_accuracy: 0.9728\n",
      "Epoch 139/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6012 - accuracy: 0.7818\n",
      "Epoch 139: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.7835 - val_loss: 0.2414 - val_accuracy: 0.9728\n",
      "Epoch 140/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.5771 - accuracy: 0.7862\n",
      "Epoch 140: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5916 - accuracy: 0.7840 - val_loss: 0.2371 - val_accuracy: 0.9728\n",
      "Epoch 141/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6224 - accuracy: 0.7719\n",
      "Epoch 141: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6224 - accuracy: 0.7719 - val_loss: 0.2396 - val_accuracy: 0.9705\n",
      "Epoch 142/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6137 - accuracy: 0.7754\n",
      "Epoch 142: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6143 - accuracy: 0.7752 - val_loss: 0.2471 - val_accuracy: 0.9628\n",
      "Epoch 143/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6291 - accuracy: 0.7715\n",
      "Epoch 143: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6184 - accuracy: 0.7747 - val_loss: 0.2437 - val_accuracy: 0.9721\n",
      "Epoch 144/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.6176 - accuracy: 0.7703\n",
      "Epoch 144: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.7693 - val_loss: 0.2387 - val_accuracy: 0.9713\n",
      "Epoch 145/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6088 - accuracy: 0.7714\n",
      "Epoch 145: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.7700 - val_loss: 0.2422 - val_accuracy: 0.9690\n",
      "Epoch 146/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 0.6075 - accuracy: 0.7824\n",
      "Epoch 146: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5974 - accuracy: 0.7838 - val_loss: 0.2378 - val_accuracy: 0.9713\n",
      "Epoch 147/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.6178 - accuracy: 0.7712\n",
      "Epoch 147: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6171 - accuracy: 0.7721 - val_loss: 0.2440 - val_accuracy: 0.9721\n",
      "Epoch 148/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.5886 - accuracy: 0.7913\n",
      "Epoch 148: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5886 - accuracy: 0.7900 - val_loss: 0.2363 - val_accuracy: 0.9721\n",
      "Epoch 149/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.5918 - accuracy: 0.7810\n",
      "Epoch 149: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5935 - accuracy: 0.7804 - val_loss: 0.2385 - val_accuracy: 0.9682\n",
      "Epoch 150/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.7799\n",
      "Epoch 150: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5978 - accuracy: 0.7799 - val_loss: 0.2416 - val_accuracy: 0.9666\n",
      "Epoch 151/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.7760\n",
      "Epoch 151: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6135 - accuracy: 0.7760 - val_loss: 0.2390 - val_accuracy: 0.9713\n",
      "Epoch 152/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5953 - accuracy: 0.7875\n",
      "Epoch 152: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.7874 - val_loss: 0.2443 - val_accuracy: 0.9705\n",
      "Epoch 153/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.5960 - accuracy: 0.7837\n",
      "Epoch 153: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.7822 - val_loss: 0.2373 - val_accuracy: 0.9713\n",
      "Epoch 154/1000\n",
      "18/31 [================>.............] - ETA: 0s - loss: 0.5899 - accuracy: 0.7899\n",
      "Epoch 154: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5868 - accuracy: 0.7874 - val_loss: 0.2415 - val_accuracy: 0.9690\n",
      "Epoch 155/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6024 - accuracy: 0.7807\n",
      "Epoch 155: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6083 - accuracy: 0.7786 - val_loss: 0.2481 - val_accuracy: 0.9666\n",
      "Epoch 156/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.5921 - accuracy: 0.7853\n",
      "Epoch 156: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5857 - accuracy: 0.7876 - val_loss: 0.2341 - val_accuracy: 0.9721\n",
      "Epoch 157/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.7909\n",
      "Epoch 157: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6002 - accuracy: 0.7910 - val_loss: 0.2354 - val_accuracy: 0.9690\n",
      "Epoch 158/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6181 - accuracy: 0.7758\n",
      "Epoch 158: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6202 - accuracy: 0.7750 - val_loss: 0.2426 - val_accuracy: 0.9674\n",
      "Epoch 159/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.7982\n",
      "Epoch 159: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5807 - accuracy: 0.7982 - val_loss: 0.2405 - val_accuracy: 0.9697\n",
      "Epoch 160/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6119 - accuracy: 0.7786\n",
      "Epoch 160: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6115 - accuracy: 0.7788 - val_loss: 0.2366 - val_accuracy: 0.9713\n",
      "Epoch 161/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6180 - accuracy: 0.7705\n",
      "Epoch 161: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.7688 - val_loss: 0.2440 - val_accuracy: 0.9674\n",
      "Epoch 162/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6005 - accuracy: 0.7829\n",
      "Epoch 162: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.5975 - accuracy: 0.7843 - val_loss: 0.2399 - val_accuracy: 0.9674\n",
      "Epoch 163/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5874 - accuracy: 0.7902\n",
      "Epoch 163: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5874 - accuracy: 0.7902 - val_loss: 0.2418 - val_accuracy: 0.9666\n",
      "Epoch 164/1000\n",
      "17/31 [===============>..............] - ETA: 0s - loss: 0.5738 - accuracy: 0.7872\n",
      "Epoch 164: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5755 - accuracy: 0.7869 - val_loss: 0.2327 - val_accuracy: 0.9744\n",
      "Epoch 165/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.5977 - accuracy: 0.7804\n",
      "Epoch 165: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5962 - accuracy: 0.7814 - val_loss: 0.2353 - val_accuracy: 0.9682\n",
      "Epoch 166/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.7848\n",
      "Epoch 166: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5897 - accuracy: 0.7848 - val_loss: 0.2402 - val_accuracy: 0.9666\n",
      "Epoch 167/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6091 - accuracy: 0.7822\n",
      "Epoch 167: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6133 - accuracy: 0.7788 - val_loss: 0.2371 - val_accuracy: 0.9674\n",
      "Epoch 168/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5998 - accuracy: 0.7768\n",
      "Epoch 168: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5985 - accuracy: 0.7773 - val_loss: 0.2350 - val_accuracy: 0.9690\n",
      "Epoch 169/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.5940 - accuracy: 0.7837\n",
      "Epoch 169: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5942 - accuracy: 0.7850 - val_loss: 0.2349 - val_accuracy: 0.9697\n",
      "Epoch 170/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.5923 - accuracy: 0.7870\n",
      "Epoch 170: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.5955 - accuracy: 0.7835 - val_loss: 0.2375 - val_accuracy: 0.9682\n",
      "Epoch 171/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.5971 - accuracy: 0.7838\n",
      "Epoch 171: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5958 - accuracy: 0.7832 - val_loss: 0.2333 - val_accuracy: 0.9728\n",
      "Epoch 172/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.5813 - accuracy: 0.7905\n",
      "Epoch 172: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5792 - accuracy: 0.7913 - val_loss: 0.2330 - val_accuracy: 0.9690\n",
      "Epoch 173/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.6116 - accuracy: 0.7724\n",
      "Epoch 173: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6162 - accuracy: 0.7719 - val_loss: 0.2272 - val_accuracy: 0.9666\n",
      "Epoch 174/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.6092 - accuracy: 0.7821\n",
      "Epoch 174: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6029 - accuracy: 0.7830 - val_loss: 0.2360 - val_accuracy: 0.9697\n",
      "Epoch 175/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5984 - accuracy: 0.7862\n",
      "Epoch 175: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5977 - accuracy: 0.7863 - val_loss: 0.2341 - val_accuracy: 0.9690\n",
      "Epoch 176/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.5923 - accuracy: 0.7843\n",
      "Epoch 176: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5862 - accuracy: 0.7850 - val_loss: 0.2298 - val_accuracy: 0.9682\n",
      "Epoch 177/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.6007 - accuracy: 0.7820\n",
      "Epoch 177: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5992 - accuracy: 0.7830 - val_loss: 0.2303 - val_accuracy: 0.9705\n",
      "Epoch 178/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.5872 - accuracy: 0.7877\n",
      "Epoch 178: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5811 - accuracy: 0.7892 - val_loss: 0.2328 - val_accuracy: 0.9666\n",
      "Epoch 179/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.5977 - accuracy: 0.7818\n",
      "Epoch 179: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5938 - accuracy: 0.7817 - val_loss: 0.2305 - val_accuracy: 0.9682\n",
      "Epoch 180/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5835 - accuracy: 0.7889\n",
      "Epoch 180: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5835 - accuracy: 0.7889 - val_loss: 0.2235 - val_accuracy: 0.9697\n",
      "Epoch 181/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.5915 - accuracy: 0.7937\n",
      "Epoch 181: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5949 - accuracy: 0.7910 - val_loss: 0.2249 - val_accuracy: 0.9682\n",
      "Epoch 182/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 0.5881 - accuracy: 0.7858\n",
      "Epoch 182: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5898 - accuracy: 0.7840 - val_loss: 0.2259 - val_accuracy: 0.9705\n",
      "Epoch 183/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.5890 - accuracy: 0.7865\n",
      "Epoch 183: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5820 - accuracy: 0.7884 - val_loss: 0.2217 - val_accuracy: 0.9682\n",
      "Epoch 184/1000\n",
      "16/31 [==============>...............] - ETA: 0s - loss: 0.5596 - accuracy: 0.8071\n",
      "Epoch 184: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5956 - accuracy: 0.7944 - val_loss: 0.2328 - val_accuracy: 0.9666\n",
      "Epoch 185/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.7850\n",
      "Epoch 185: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6083 - accuracy: 0.7850 - val_loss: 0.2354 - val_accuracy: 0.9666\n",
      "Epoch 186/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5898 - accuracy: 0.7878\n",
      "Epoch 186: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5892 - accuracy: 0.7879 - val_loss: 0.2328 - val_accuracy: 0.9690\n",
      "Epoch 187/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.5949 - accuracy: 0.7799\n",
      "Epoch 187: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6003 - accuracy: 0.7822 - val_loss: 0.2257 - val_accuracy: 0.9690\n",
      "Epoch 188/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.5959 - accuracy: 0.7847\n",
      "Epoch 188: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5955 - accuracy: 0.7858 - val_loss: 0.2312 - val_accuracy: 0.9682\n",
      "Epoch 189/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.6029 - accuracy: 0.7779\n",
      "Epoch 189: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6037 - accuracy: 0.7778 - val_loss: 0.2358 - val_accuracy: 0.9690\n",
      "Epoch 190/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.5726 - accuracy: 0.7891\n",
      "Epoch 190: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5785 - accuracy: 0.7884 - val_loss: 0.2323 - val_accuracy: 0.9674\n",
      "Epoch 191/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.7975\n",
      "Epoch 191: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5729 - accuracy: 0.7975 - val_loss: 0.2355 - val_accuracy: 0.9643\n",
      "Epoch 192/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.5680 - accuracy: 0.7939\n",
      "Epoch 192: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5760 - accuracy: 0.7910 - val_loss: 0.2263 - val_accuracy: 0.9690\n",
      "Epoch 193/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 0.5902 - accuracy: 0.7875\n",
      "Epoch 193: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.5906 - accuracy: 0.7850 - val_loss: 0.2279 - val_accuracy: 0.9659\n",
      "Epoch 194/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.5727 - accuracy: 0.7963\n",
      "Epoch 194: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5780 - accuracy: 0.7938 - val_loss: 0.2336 - val_accuracy: 0.9651\n",
      "Epoch 195/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5807 - accuracy: 0.7891\n",
      "Epoch 195: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5825 - accuracy: 0.7879 - val_loss: 0.2350 - val_accuracy: 0.9659\n",
      "Epoch 196/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.5936 - accuracy: 0.7796\n",
      "Epoch 196: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5909 - accuracy: 0.7794 - val_loss: 0.2300 - val_accuracy: 0.9721\n",
      "Epoch 197/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 0.5772 - accuracy: 0.7951\n",
      "Epoch 197: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5734 - accuracy: 0.7949 - val_loss: 0.2259 - val_accuracy: 0.9674\n",
      "Epoch 198/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 0.5842 - accuracy: 0.7913\n",
      "Epoch 198: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.7915 - val_loss: 0.2268 - val_accuracy: 0.9721\n",
      "Epoch 199/1000\n",
      "15/31 [=============>................] - ETA: 0s - loss: 0.5758 - accuracy: 0.7937\n",
      "Epoch 199: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5767 - accuracy: 0.7944 - val_loss: 0.2301 - val_accuracy: 0.9635\n",
      "Epoch 200/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5977 - accuracy: 0.7852\n",
      "Epoch 200: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5989 - accuracy: 0.7843 - val_loss: 0.2265 - val_accuracy: 0.9682\n",
      "Epoch 201/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 0.6015 - accuracy: 0.7734\n",
      "Epoch 201: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5988 - accuracy: 0.7768 - val_loss: 0.2328 - val_accuracy: 0.9643\n",
      "Epoch 202/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5821 - accuracy: 0.7859\n",
      "Epoch 202: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5812 - accuracy: 0.7863 - val_loss: 0.2295 - val_accuracy: 0.9666\n",
      "Epoch 203/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.7909\n",
      "Epoch 203: saving model to C:\\VS CODE\\computer vision\\openCV\\BasicManipulation\\OpenCv-projects\\pythonAutoGUI\\hand-gesture-recognition-mediapipe-main (1)\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5756 - accuracy: 0.7923 - val_loss: 0.2226 - val_accuracy: 0.9682\n",
      "Epoch 203: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x223c20b4290>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "[5.6567616e-03 8.8857114e-02 9.0215451e-01 3.8950511e-05 3.2907608e-03\n",
      " 1.8957735e-06]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       400\n",
      "           1       0.99      0.92      0.95       369\n",
      "           2       0.92      0.99      0.96       349\n",
      "           3       1.00      0.99      0.99        81\n",
      "           4       1.00      0.95      0.98        43\n",
      "           5       0.98      1.00      0.99        47\n",
      "\n",
      "    accuracy                           0.97      1289\n",
      "   macro avg       0.98      0.97      0.98      1289\n",
      "weighted avg       0.97      0.97      0.97      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\samma\\AppData\\Local\\Temp\\tmph18ngjyv\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\samma\\AppData\\Local\\Temp\\tmph18ngjyv\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6660"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.6567616e-03 8.8857092e-02 9.0215451e-01 3.8950435e-05 3.2907608e-03\n",
      " 1.8957699e-06]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
