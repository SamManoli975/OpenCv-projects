{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samma\\anaconda3\\envs\\env1\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe FaceMesh and Drawing utilities\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Specify directory with known faces\n",
    "KNOWN_FACES_DIR = 'known_faces'\n",
    "known_face_embeddings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Function to calculate face embeddings using MediaPipe FaceMesh landmarks\n",
    "def get_face_embedding(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1) as face_mesh:\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if not results.multi_face_landmarks:\n",
    "            return None\n",
    "        # Extract the first (and only) face landmarks\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "        # Convert landmarks to a flat numpy array as an \"embedding\"\n",
    "        embedding = np.array([[landmark.x, landmark.y, landmark.z] for landmark in face_landmarks.landmark]).flatten()\n",
    "        return embedding\n",
    "\n",
    "# Load and process each known face to compute embeddings\n",
    "for filename in os.listdir(KNOWN_FACES_DIR):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(KNOWN_FACES_DIR, filename)\n",
    "        embedding = get_face_embedding(image_path)\n",
    "        if embedding is not None:\n",
    "            known_face_embeddings.append(embedding)\n",
    "            known_face_names.append(os.path.splitext(filename)[0])\n",
    "\n",
    "# Function to compute Euclidean distance between two embeddings\n",
    "def compute_distance(embedding1, embedding2):\n",
    "    return np.linalg.norm(embedding1 - embedding2)\n",
    "\n",
    "# Threshold for recognizing a face (tuned based on trial and error)\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "# For webcam input\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Convert the frame to RGB for processing\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Get the embedding of the detected face\n",
    "                embedding = np.array([[landmark.x, landmark.y, landmark.z] for landmark in face_landmarks.landmark]).flatten()\n",
    "\n",
    "                # Initialize best match variables\n",
    "                best_match_name = \"Unknown\"\n",
    "                best_match_distance = float('inf')\n",
    "\n",
    "                # Compare with each known face\n",
    "                for i, known_embedding in enumerate(known_face_embeddings):\n",
    "                    distance = compute_distance(embedding, known_embedding)\n",
    "                    if distance < best_match_distance and distance < THRESHOLD:\n",
    "                        best_match_distance = distance\n",
    "                        best_match_name = known_face_names[i]\n",
    "\n",
    "                # Display the result on the frame\n",
    "                frame_height, frame_width, _ = frame.shape\n",
    "                x_min = int(face_landmarks.landmark[0].x * frame_width)  # Example x-coordinate for positioning text\n",
    "                y_min = int(face_landmarks.landmark[0].y * frame_height) - 10  # Example y-coordinate for positioning text\n",
    "\n",
    "                # Draw landmarks and label the face\n",
    "                mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS)\n",
    "                cv2.putText(frame, best_match_name, (x_min, y_min), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('MediaPipe Face Recognition (Lightweight)', cv2.flip(frame, 1))\n",
    "\n",
    "        # Break on ESC key\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
